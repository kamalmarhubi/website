<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kamal Marhubi</title>
    <description></description>
    <link>http://kamalmarhubi.com/</link>
    <atom:link href="http://kamalmarhubi.com/blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 06 Sep 2015 12:04:00 -0400</pubDate>
    <lastBuildDate>Sun, 06 Sep 2015 12:04:00 -0400</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Kubernetes from the ground up: the API server</title>
        <description>&lt;p&gt;&lt;em&gt;This is the second post in a series on &lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;, the open source cluster
manager. The first post was &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/&quot;&gt;about the kubelet&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/&quot;&gt;Last time&lt;/a&gt; we took a look at the kubelet, Kubernetes’
container-focused process watcher. The kubelet runs pods, which are collections
of containers that share an IP and some volumes. In the post, we gave it pods
to run by putting pod manifest files in directory it watched. This was a great
way to understand the core purpose of the kubelet.  In a Kubernetes cluster,
however, a kubelet will get most its pods to run from the Kubernetes API
server.&lt;/p&gt;

&lt;p&gt;Kubernetes stores all its cluster state in &lt;a href=&quot;https://github.com/coreos/etcd&quot;&gt;etcd&lt;/a&gt;, a distributed data store with
a strong consistency model. This state includes what nodes exist in the cluster,
what pods should be running, which nodes they are running on, and a whole lot
more. The API server is the only Kubernetes component that connects to etcd; all
the other components must go through the API server to work with cluster state.
In this post we’ll look at the API server, and its interaction with the kubelet.&lt;/p&gt;

&lt;h1 id=&quot;starting-the-api-server&quot;&gt;Starting the API server&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;You may need to use &lt;code&gt;sudo&lt;/code&gt; on some commands, depending on your setup.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;First off, we’re going to need etcd running. Luckily this is as easy as creating
a directory for it to store its state and starting it with Docker. We’ll also
save the Docker container ID so we can stop the container later.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir etcd-data
$ docker run --volume=$PWD/etcd-data:/default.etcd \
--detach --net=host quay.io/coreos/etcd &amp;gt; etcd-container-id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use host networking so that the API server can talk to it at &lt;code&gt;127.0.0.1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next we’ll want the API server binary:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://storage.googleapis.com/kubernetes-release/release/v1.0.3/bin/linux/amd64/kube-apiserver
$ chmod +x kube-apiserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can start it up. It needs to know where the etcd server is, as well as
the service cluster IP range. We’ll save talking about what the IP range is for
a later post that will go into Kubernetes’ services and networking. For now
we’ll just provide &lt;code&gt;10.0.0.0/16&lt;/code&gt; so that the API server starts up without
shouting at us!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kube-apiserver \
--etcd-servers=http://127.0.0.1:2379 \
--service-cluster-ip-range=10.0.0.0/16 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now &lt;code&gt;curl&lt;/code&gt; around and check a few things out. First off, we can get a
list of nodes in our cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:8080/api/v1/nodes
{
  &quot;kind&quot;: &quot;NodeList&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    &quot;selfLink&quot;: &quot;/api/v1/nodes&quot;,
    &quot;resourceVersion&quot;: &quot;150&quot;
  },
  &quot;items&quot;: []
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not surprisingly, there aren’t any yet.&lt;/p&gt;

&lt;p&gt;As a quick note on other fields in the response: the &lt;code&gt;kind&lt;/code&gt; and &lt;code&gt;apiVersion&lt;/code&gt;
are giving information about the API version and type of response we got. The
&lt;code&gt;selfLink&lt;/code&gt; field is a canonical link for the resource in the response. The
&lt;code&gt;resourceVersion&lt;/code&gt; is used for concurrency control. Clients send it back when
they are changing a resource, and the server can determine if there was a
conflicting write to the same resource in the meantime.&lt;/p&gt;

&lt;p&gt;All that is to say: right now we only care about the &lt;code&gt;items&lt;/code&gt; field. We can use
the incredibly handy &lt;a href=&quot;https://stedolan.github.io/jq/&quot;&gt;&lt;code&gt;jq&lt;/code&gt;&lt;/a&gt; utility to just get at the items. We’ll use &lt;code&gt;jq&lt;/code&gt;
to cut out noisy bits of responses throughout this post. For example, we can
look at what pods our cluster is running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:8080/api/v1/pods | jq &#39;.items&#39;
[]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No surprises there, either!&lt;/p&gt;

&lt;h1 id=&quot;adding-a-node&quot;&gt;Adding a node&lt;/h1&gt;

&lt;p&gt;In the last post, we had the kubelet watching for pod manifest files in a
directory we gave it via the &lt;code&gt;--config&lt;/code&gt; flag. This time we’ll have it get pod
manifests from the API server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubelet --api-servers=127.0.0.1:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When a kubelet starts up, it registers itself as a node with the API server and
starts watching for pods to run. This is really great, because it means that
when we get to running a multinode cluster, we can add nodes without having to
reconfigure the API server.&lt;/p&gt;

&lt;p&gt;We can check that the API server knows about our node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:8080/api/v1/nodes/ \
| jq &#39;.items&#39; | head
[
  {
    &quot;metadata&quot;: {
      &quot;name&quot;: &quot;awesome-node&quot;,
      &quot;selfLink&quot;: &quot;/api/v1/nodes/awesome-node&quot;,
      &quot;uid&quot;: &quot;6811f7b0-5181-11e5-b364-68f7288bdc45&quot;,
      &quot;resourceVersion&quot;: &quot;246&quot;,
      &quot;creationTimestamp&quot;: &quot;2015-09-02T14:46:34Z&quot;,
      &quot;labels&quot;: {
        &quot;kubernetes.io/hostname&quot;: &quot;awesome-node&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have a one-node cluster!&lt;/p&gt;

&lt;h1 id=&quot;running-a-pod-via-the-api-server&quot;&gt;Running a pod via the API server&lt;/h1&gt;

&lt;p&gt;Let’s run our nginx example from the last post:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/01-the-kubelet/nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In a complete Kubernetes cluster, the scheduler will decide which node to run a
pod on. For now, we’ve only got the API server and a kubelet, so we’ll have to
specify it ourselves. To do this, we need to add a &lt;code&gt;nodeName&lt;/code&gt; to the spec with
the node’s &lt;code&gt;name&lt;/code&gt; from above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sed --in-place &#39;/spec:/a\ \ nodeName: awesome-node&#39; nginx.yaml
$ head nginx.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: awesome-node
  containers:
  - name: nginx
    image: nginx
    ports:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the &lt;code&gt;nodeName&lt;/code&gt; configured, we’re almost ready to send the pod manifest to
the API server. Unfortunately, it only speaks JSON so we have to convert our YAML to
JSON:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ruby -ryaml -rjson \
-e &#39;puts JSON.pretty_generate(YAML.load(ARGF))&#39; &amp;lt; nginx.yaml &amp;gt; nginx.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, just download the &lt;a href=&quot;https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.json&quot;&gt;JSON file&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.yaml&quot;&gt;YAML
file&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.json
$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then edit the files so that the &lt;code&gt;nodeName&lt;/code&gt; matches your hostname.&lt;/p&gt;

&lt;p&gt;Now we can post the JSON pod manifest to the API server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl \
--stderr /dev/null \
--request POST http://localhost:8080/api/v1/namespaces/default/pods \
--data @nginx.json | jq &#39;del(.spec.containers, .spec.volumes)&#39;
{
  &quot;kind&quot;: &quot;Pod&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    &quot;name&quot;: &quot;nginx&quot;,
    &quot;namespace&quot;: &quot;default&quot;,
    &quot;selfLink&quot;: &quot;/api/v1/namespaces/default/pods/nginx&quot;,
    &quot;uid&quot;: &quot;28aa5a55-5194-11e5-b364-68f7288bdc45&quot;,
    &quot;resourceVersion&quot;: &quot;1365&quot;,
    &quot;creationTimestamp&quot;: &quot;2015-09-02T17:00:48Z&quot;
  },
  &quot;spec&quot;: {
    &quot;restartPolicy&quot;: &quot;Always&quot;,
    &quot;dnsPolicy&quot;: &quot;ClusterFirst&quot;,
    &quot;nodeName&quot;: &quot;awesome-node&quot;
  },
  &quot;status&quot;: {
    &quot;phase&quot;: &quot;Pending&quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a short wait, the kubelet should have started the pod. We can check this
by making a GET request:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:8080/api/v1/namespaces/default/pods \
| jq &#39;.items[] | { name: .metadata.name, status: .status} | del(.status.containerStatuses)&#39;
{
  &quot;name&quot;: &quot;nginx&quot;,
  &quot;status&quot;: {
    &quot;phase&quot;: &quot;Running&quot;,
    &quot;conditions&quot;: [
      {
        &quot;type&quot;: &quot;Ready&quot;,
        &quot;status&quot;: &quot;True&quot;
      }
    ],
    &quot;hostIP&quot;: &quot;127.0.1.1&quot;,
    &quot;podIP&quot;: &quot;172.17.0.37&quot;,
    &quot;startTime&quot;: &quot;2015-09-02T18:00:00Z&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The pod is up, and it’s been assigned the IP &lt;code&gt;172.17.0.37&lt;/code&gt; by Docker. Docker
networking is really quite interesting, and well worth reading about. A good
place to start is &lt;a href=&quot;https://docs.docker.com/articles/networking/&quot;&gt;the network configuration article&lt;/a&gt; in the Docker
documentation.&lt;/p&gt;

&lt;p&gt;Let’s check that nginx is reachable at that IP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://172.17.0.37 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Excellent!&lt;/p&gt;

&lt;h1 id=&quot;the-kubernetes-command-line-client-kubectl&quot;&gt;The Kubernetes command line client: kubectl&lt;/h1&gt;

&lt;p&gt;While it’s great to know that the API server speaks a fairly intelligible REST
dialect, talking to it directly with &lt;code&gt;curl&lt;/code&gt; and using &lt;code&gt;jq&lt;/code&gt; to filter the
responses isn’t the best user experience. This is a great point to pause and
introduce the command line client&lt;a href=&quot;http://kubernetes.io/v1.0/docs/user-guide/kubectl/kubectl.html&quot;&gt; &lt;code&gt;kubectl&lt;/code&gt;&lt;/a&gt;, which we’ll use
throughout the rest of this series. It will make things &lt;strong&gt;much&lt;/strong&gt; nicer!&lt;/p&gt;

&lt;p&gt;First off, let’s download the client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://storage.googleapis.com/kubernetes-release/release/v1.0.3/bin/linux/amd64/kubectl
$ chmod +x kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can get the list of nodes and see what pods are running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl get nodes
NAME      LABELS                      STATUS
awesome-node        kubernetes.io/hostname=awesome-node   Ready
$ ./kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
nginx     2/2       Running   0          28m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much easier and prettier! Creating pods is also easier with &lt;code&gt;kubectl&lt;/code&gt;. Let’s
create a copy of the nginx pod manifest with a different name.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sed &#39;s/^  name:.*/  name: nginx-the-second/&#39; nginx.yaml &amp;gt; nginx2.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can use &lt;code&gt;kubectl create&lt;/code&gt; to start another copy.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl create --filename nginx2.yaml
pods/nginx-the-second
$ ./kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
nginx              2/2       Running   0          1h
nginx-the-second   0/2       Running   0          6s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we’ve got our second nginx pod running, but it reports &lt;code&gt;0/2&lt;/code&gt; containers
running. Let’s give it a bit and try again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
nginx              2/2       Running   0          1h
nginx-the-second   2/2       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also use &lt;code&gt;kubectl describe&lt;/code&gt; to get at more detailed information on the
pod:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl describe pods/nginx-the-second | head
Name:                           nginx-the-second
Namespace:                      default
Image(s):                       nginx,busybox
Node:                           awesome-node/127.0.1.1
Labels:                         &amp;lt;none&amp;gt;
Status:                         Running
Reason:
Message:
IP:                             172.17.0.38
Replication Controllers:        &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And just to be sure, we can check that this pod’s nginx is also up and serving
requests at the pod’s IP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://172.17.0.38 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! So now we’ve seen what it’s like to start a server in Kubernetes using
the command line client. We’ve still got a little way to go before this is a
full-blown Kubernetes cluster, but we are inching closer. Next time we’ll bring
in the scheduler and add a couple more nodes into the mix.&lt;/p&gt;

&lt;p&gt;For now, let’s just tear everything down:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl delete pods/nginx pods/nginx-the-second
pods/nginx
pods/nginx-the-second
$ ./kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
$ docker stop $(cat etcd-container-id)
$ sleep 20  # wait for the Kubelet to stop all the containers
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sun, 06 Sep 2015 12:02:47 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/</guid>
        
        
      </item>
    
      <item>
        <title>What even is a kubelet?</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; is Google’s open source, container-focused cluster management
thing.  I see it as their attempt to tell everyone how they think containers
and clusters fit together. The Kubernetes documentation is quite good, but it’s
divided up in a way that makes it great as a reference. I want to understand
both the concepts Kubernetes introduces, and the components that make up a
Kubernetes cluster, and I want to learn by doing. I’m planning to build up a
cluster from scratch, documenting the moving parts and concepts as I go.&lt;/p&gt;

&lt;p&gt;I’ll start of with a look at the &lt;em&gt;&lt;a href=&quot;http://kubernetes.io/v1.0/docs/admin/kubelet.html&quot;&gt;kubelet&lt;/a&gt;&lt;/em&gt;, which is the lowest level component
in Kubernetes. It’s responsible for what’s running on an individual machine.
You can think of it as a process watcher like &lt;a href=&quot;http://supervisord.org/&quot;&gt;supervisord&lt;/a&gt;, but focused on
running containers. It has one job: given a set of containers to run, make sure
they are all running.&lt;/p&gt;

&lt;h1 id=&quot;kubelets-run-pods&quot;&gt;Kubelets run pods&lt;/h1&gt;

&lt;p&gt;The unit of execution that Kubernetes works with is the &lt;em&gt;&lt;a href=&quot;http://kubernetes.io/v1.0/docs/user-guide/pods.html&quot;&gt;pod&lt;/a&gt;&lt;/em&gt;. A pod is a
collection of containers that share some resources: they have a single IP, and
can share volumes. For example, a web server pod could have a container for the
server itself, and a container that tails the logs and ships them off to your
logging or metrics infrastructure.&lt;/p&gt;

&lt;p&gt;Pods are defined by a JSON or YAML file called a pod manifest. A simple one
with one container looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The container’s &lt;code&gt;image&lt;/code&gt; is a Docker image name. The &lt;code&gt;containerPort&lt;/code&gt; exposes
that port from the nginx container so we can connect to the nginx server at the
pod’s IP. By default, the &lt;a href=&quot;http://docs.docker.com/reference/builder/#entrypoint&quot;&gt;entrypoint&lt;/a&gt; defined in the image is what will run; in
the nginx image, that’s the nginx server.&lt;/p&gt;

&lt;p&gt;Let’s add a log truncator container to this pod. This will take care of the
nginx access log, truncating it every 10 seconds—who needs those anyway? To do
this, we’ll need nginx to write its logs to a volume that can be shared to the
log truncator. We’ll set this volume up as an &lt;code&gt;emptyDir&lt;/code&gt; volume: it will start
off as an empty directory when the pod starts, and be cleaned up when the pod
exits, but will persist across restarts of the component containers.&lt;/p&gt;

&lt;p&gt;Here’s the updated pod manifest:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    volumeMounts:
    - mountPath: /var/log/nginx
      name: nginx-logs
  - name: log-truncator
    image: busybox
    command:
    - /bin/sh
    args: [-c, &#39;while true; do cat /dev/null &amp;gt; /logdir/access.log; sleep 10; done&#39;]
    volumeMounts:
    - mountPath: /logdir
      name: nginx-logs
  volumes:
  - name: nginx-logs
    emptyDir: {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We’ve added an &lt;code&gt;emptyDir&lt;/code&gt; volume named &lt;code&gt;nginx-logs&lt;/code&gt;. nginx writes its logs at
/var/log/nginx, so we mount that volume at that location in the &lt;code&gt;nginx&lt;/code&gt;
container. For the &lt;code&gt;log-truncator&lt;/code&gt; container, we’re using the &lt;a href=&quot;https://hub.docker.com/_/busybox/&quot;&gt;busybox&lt;/a&gt; image.
It’s a tiny Linux command line environment, which provides everything we need
for a robust log truncator. Inside that container, we’ve mounted the
&lt;code&gt;nginx-logs&lt;/code&gt; volume at &lt;code&gt;/logdir&lt;/code&gt;. We set its &lt;code&gt;command&lt;/code&gt; and &lt;code&gt;args&lt;/code&gt; up to run a
shell loop that truncates the log file every 10 seconds.&lt;/p&gt;

&lt;p&gt;Now we’ve got this paragon of production infrastructure configured, it’s time
to run it!&lt;/p&gt;

&lt;h1 id=&quot;running-a-pod&quot;&gt;Running a pod&lt;/h1&gt;

&lt;p&gt;There are a few ways the kubelet finds pods to run:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a directory it polls for new pod manifests to run&lt;/li&gt;
  &lt;li&gt;a URL it polls and downloads pod manifests from&lt;/li&gt;
  &lt;li&gt;from the Kubernetes API server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first of these is definitely the simplest: to run a pod, we just put a
manifest file in the watched directory. Every 20 seconds, the kubelet checks
for changes in the directory, and adjusts what it’s running based on what it
finds.  This means both launching pods that are added, as well as killing ones
that are removed.&lt;/p&gt;

&lt;p&gt;The kubelet is such a low level component with such limited responsibilities
that we can actually use it independently of Kubernetes—all we have to do is
not tell it about a Kubernetes API server. The kubelet supports &lt;a href=&quot;https://github.com/docker/docker&quot;&gt;Docker&lt;/a&gt; and
&lt;a href=&quot;https://github.com/coreos/rkt&quot;&gt;rkt&lt;/a&gt; as continer runtimes. The default is Docker, and that’s what we’ll use in
the examples here. You’ll need a machine with Docker installed and running to
try this out.&lt;/p&gt;

&lt;p&gt;First off, let’s get the kubelet binary from Google.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://storage.googleapis.com/kubernetes-release/release/v1.0.3/bin/linux/amd64/kubelet
$ chmod +x kubelet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you run &lt;code&gt;./kubelet --help&lt;/code&gt;, you’ll get an overwhelming list of options. For
what we’re about to do, we only need one of them though: the &lt;code&gt;--config&lt;/code&gt; option.
This is the directory that the kubelet will watch for pod manifests to run.
We’ll create a directory for this, and then start the kubelet. You might need
to run it under &lt;code&gt;sudo&lt;/code&gt; so that it can talk to the docker daemon.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir manifests
$ ./kubelet --config=$PWD/manifests
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let’s stick the example nginx pod manifest from above in an &lt;code&gt;nginx.yaml&lt;/code&gt;
file, and then drop it in the &lt;code&gt;manifests&lt;/code&gt; directory. After a short wait, the
kubelet will notice the file and fire up the pod.&lt;/p&gt;

&lt;p&gt;We can check the list of running containers with &lt;code&gt;docker ps&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
CONTAINER ID        IMAGE                                  COMMAND                CREATED             STATUS              PORTS               NAMES
f1a27680e401        busybox:latest                         &quot;/bin/sh -c &#39;while t   6 seconds ago       Up 5 seconds                            k8s_log-truncator.72cfff7a_nginx-kx_default_419bc51e985b6bb5e53ea305e2c1e737_401a4c94   
c5e357fc981a        nginx:latest                           &quot;nginx -g &#39;daemon of   6 seconds ago       Up 6 seconds                            k8s_nginx.515d0778_nginx-kx_default_419bc51e985b6bb5e53ea305e2c1e737_cd02602b           
b2692643c372        gcr.io/google_containers/pause:0.8.0   &quot;/pause&quot;               6 seconds ago       Up 6 seconds                            k8s_POD.ef28e851_nginx-kx_default_419bc51e985b6bb5e53ea305e2c1e737_836cadc7             
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are three containers running: the &lt;code&gt;nginx&lt;/code&gt; and &lt;code&gt;log-truncator&lt;/code&gt; containers
we defined, as well as the pod infrastructure container.&lt;sup id=&quot;fnref:pause&quot;&gt;&lt;a href=&quot;#fn:pause&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; The
infrastructure container is where the kubelet puts all the resources that are
shared across containers in the pod. This includes the IP, as well as any
volumes we’ve defined. We can poke around with &lt;code&gt;docker inspect&lt;/code&gt; to see how
they’re configured and hooked up to each other:&lt;/p&gt;

&lt;!-- annoying quoting needed because liquid templates use  for something --&gt;
&lt;pre&gt;&lt;code&gt;$ docker inspect --format &#39;{{ .NetworkSettings.IPAddress  }}&#39; f1a27680e401

$ docker inspect --format &#39;{{ .NetworkSettings.IPAddress  }}&#39; c5e357fc981a

$ docker inspect --format &#39;{{ .NetworkSettings.IPAddress  }}&#39; b2692643c372
172.17.0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The nginx and log trunctator containers have no IP, but the infrastructure container does. Taking a
closer look at at the containers we defined, we can see their &lt;code&gt;NetworkMode&lt;/code&gt; is set to
use the infrastructure container’s network:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect --format &#39;{{ .HostConfig.NetworkMode  }}&#39; c5e357fc981a
container:b2692643c37216c3f1650b4a5b96254270e0489b96c022c9873ad63c4809ce93
$ docker inspect --format &#39;{{ .HostConfig.NetworkMode  }}&#39; f1a27680e401
container:b2692643c37216c3f1650b4a5b96254270e0489b96c022c9873ad63c4809ce93
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since we exposed port 80 from the nginx container with &lt;code&gt;containerPort&lt;/code&gt;,
we can connect to the nginx server at port 80 at the pod’s IP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://172.17.0.2 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It really is running! And just to check the log truncator is doing what we
expect, let’s watch the log file and make some requests with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec -tty f1a27680e401 watch cat /logdir/access.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;while we make a few requests. The log lines accumulate for a bit, but then they
all disappear: the truncator doing its job!&lt;/p&gt;

&lt;h1 id=&quot;kubelet-introspection&quot;&gt;Kubelet introspection&lt;/h1&gt;

&lt;p&gt;The kubelet also has an internal HTTP server. We won’t go into it in detail,
except to say that it serves a read-only view at port
10255.  There’s a health check endpoint at &lt;code&gt;/healthz&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:10255/healthz
ok
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are also a few status endpoints. For example, you can get a list
of running pods at &lt;code&gt;/pods&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:10255/pods | jq . | head
{
  &quot;kind&quot;: &quot;PodList&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {},
  &quot;items&quot;: [
    {
      &quot;metadata&quot;: {
        &quot;name&quot;: &quot;nginx-kx&quot;,
        &quot;namespace&quot;: &quot;default&quot;,
        &quot;selfLink&quot;: &quot;/api/v1/pods/namespaces/nginx-kx/default&quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also get specs of the machine the kubelet is running on at
&lt;code&gt;/spec/&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null  http://localhost:10255/spec/ | jq . | head
{
  &quot;num_cores&quot;: 4,
  &quot;cpu_frequency_khz&quot;: 2700000,
  &quot;memory_capacity&quot;: 4051689472,
  &quot;machine_id&quot;: &quot;9eacc5220f4b41e0a22972d8a47ccbe1&quot;,
  &quot;system_uuid&quot;: &quot;818B908B-D053-CB11-BC8B-EEA826EBA090&quot;,
  &quot;boot_id&quot;: &quot;a95a337d-6b54-4359-9a02-d50fb7377dd1&quot;,
  &quot;filesystems&quot;: [
    {
      &quot;device&quot;: &quot;/dev/mapper/kx--vg-root&quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;tearing-things-down&quot;&gt;Tearing things down&lt;/h1&gt;

&lt;p&gt;Finally, we can clean up after ourselves. Just deleting the nginx pod
manifest will result in the kubelet stopping the containers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ rm $PWD/manifests/nginx.yaml
$ sleep 20  # wait for the kublet to spot the removed manifest
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
$ curl --stderr /dev/null http://localhost:10255/pods
{&quot;kind&quot;:&quot;PodList&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;metadata&quot;:{},&quot;items&quot;:null}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All gone!&lt;/p&gt;

&lt;p&gt;We’ve seen that while the kubelet is a part of Kubernetes, at heart it’s a
container-oriented process watcher. You can use it in isolation to manage
containers running on a single host. In fact, the Kubernetes &lt;a href=&quot;http://kubernetes.io/v1.0/docs/getting-started-guides/docker.html#step-two-run-the-master&quot;&gt;getting started
guides for Docker&lt;/a&gt; run the kubelet under Docker and
use the kubelet to manage the Kubernetes master components. In a later post,
we’ll do something similar!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:pause&quot;&gt;

      &lt;p&gt;The &lt;code&gt;pause&lt;/code&gt; command that the infrastructure container runs is a 129 byte
ELF binary that just calls the &lt;a href=&quot;http://man7.org/linux/man-pages/man2/pause.2.html&quot;&gt;&lt;code&gt;pause&lt;/code&gt; system call&lt;/a&gt;, and
exits when a signal is received. This keeps the infrastructure container
around until the kubelet brings it down. It’s pretty cool, check the
&lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/88317efb42db763b9fb97cd1d9ac1465e62009d0/third_party/pause/pause.asm&quot;&gt;source&lt;/a&gt;! &lt;a href=&quot;#fnref:pause&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 27 Aug 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/</guid>
        
        
      </item>
    
      <item>
        <title>Recurse Center lab notes catch up</title>
        <description>&lt;p&gt;I’m way behind on posting here. Here is a quick rundown of what I’ve been up to.&lt;/p&gt;

&lt;p&gt;The biggest thing is that I managed to run &lt;a href=&quot;http://kythe.io/&quot;&gt;Kythe&lt;/a&gt;! It took me half a week to
get it to work with a hello world program, but once I had that I was good to
go. This meant I got to play with &lt;a href=&quot;http://bazel.io/&quot;&gt;Bazel&lt;/a&gt; again, which was nicely familiar.&lt;/p&gt;

&lt;p&gt;A lot of the confusion was that remote Bazel repositories don’t quite work for
C++ in the current state. My approach of referring to the Kythe indexer from a
Bazel repository with my hello world program just wasn’t going to work, even
though I kept trying. In the end, I just copied the binaries into my tree and
set up the configuration needed to run them.&lt;/p&gt;

&lt;p&gt;I gave a demo of the web UI that comes with Kythe, run against some data
structure code that had Alice written. There’s a somewhat hilarious blowup in
size: 7 kB of source results in a couple of serving database tables. I also did
a hackish port of the SQLite build over to Bazel so I could run Kythe over it.
The 1.5 MB of source resulted in a ~80 MB database. The flipside is that the
API server responds to most queries in a few milliseconds.&lt;/p&gt;

&lt;p&gt;Keeping with Kythe, I’m currently working on an alternative web UI. The
provided one is really good to understand how nodes are linked together in the
graph structure that Kythe builds up, but it’s too noisy and clunky to use as a
day-to-day code exploration tool. As an example, it shows the syntactic
relationship of a variable reference being a child of the function it occurs
in.&lt;/p&gt;

&lt;p&gt;I’m pretty excited about this project because one of the things I wanted to do
at RC was to learn JavaScript (well, ECMAScript 2015). The &lt;a href=&quot;https://github.com/google/kythe/tree/master/kythe/web/ui/src-cljs/ui&quot;&gt;Kythe web
UI&lt;/a&gt; is in &lt;a href=&quot;https://github.com/clojure/clojurescript&quot;&gt;Clojurescript&lt;/a&gt; using &lt;a href=&quot;https://github.com/omcljs/om&quot;&gt;Om&lt;/a&gt;, which I’m not currently
interested in learning, so I’ll be starting my own from scratch.&lt;/p&gt;

&lt;p&gt;Just to keep things slightly weird, I’m using &lt;a href=&quot;https://github.com/Reactive-Extensions/RxJS&quot;&gt;RxJS&lt;/a&gt;, the Reactive Extensions
for JavaScript. I’m trying to emulate the architecture used in &lt;a href=&quot;http://elm-lang.org/&quot;&gt;Elm&lt;/a&gt; in place
of the &lt;a href=&quot;http://facebook.github.io/flux/&quot;&gt;Flux&lt;/a&gt; architecture that’s more commonly used with React. The &lt;a href=&quot;https://github.com/evancz/elm-architecture-tutorial/&quot;&gt;Elm
architecture&lt;/a&gt; is pleasantly functional, consisting of&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a model type &lt;code&gt;Model&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;an action type &lt;code&gt;Action&lt;/code&gt; that specifies all the kinds of actions that exist;&lt;/li&gt;
  &lt;li&gt;an update function &lt;code&gt;update :: Action -&amp;gt; Model -&amp;gt; Model&lt;/code&gt;; and&lt;/li&gt;
  &lt;li&gt;a view function &lt;code&gt;view :: Model -&amp;gt; Html&lt;/code&gt; that renders the model.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are all wired up with functional reactive stuff—&lt;a href=&quot;http://package.elm-lang.org/packages/elm-lang/core/2.1.0/Signal&quot;&gt;Signals&lt;/a&gt; in Elm,
&lt;a href=&quot;https://github.com/Reactive-Extensions/RxJS/blob/master/doc/api/core/observable.md&quot;&gt;Observables&lt;/a&gt; in RxJS. The user input events are translated into a stream of
actions. A stream of models is created by folding the update function over the
action stream. Finally, the view is kept up to date by mapping the view
function over the model stream.&lt;/p&gt;

&lt;p&gt;I have no real idea what I’m doing, so I’m starting off with translating the
&lt;a href=&quot;https://github.com/evancz/elm-todomvc&quot;&gt;Elm TodoMVC&lt;/a&gt; implementation to this cobbled together set of
tools. This should be done fairly soon, then I’ll go back to the Kythe code
browser.&lt;/p&gt;

</description>
        <pubDate>Wed, 29 Jul 2015 00:01:49 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/07/29/recurse-center-lab-notes-catch-up/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/07/29/recurse-center-lab-notes-catch-up/</guid>
        
        
      </item>
    
      <item>
        <title>Preludes</title>
        <description>&lt;p&gt;This evening I walked from the Lincoln Center at 66th and Broadway down
to 40th street, all the while listening to Rachmaninoff’s 1929
performance of his Piano Concerto № 2. My noise cancelling headphones
masked the never ending cacophony of the city. The experience of the
third movement was slightly surreal, coinciding with my traversal of
Times Square.&lt;/p&gt;

&lt;p&gt;This was brought on by having just watched &lt;a href=&quot;http://www.lct.org/shows/preludes/&quot;&gt;Preludes&lt;/a&gt;, ‘a musical fantasia
set in the hypnotized mind of Russian composer Sergei Rachmaninoff’,
which is playing at the Lincoln Center through to August second.
Rachmaninoff suffered depression and writer’s block, and visited
hypnotherapist Nikolai Dahl to help him break through it. Rachmaninoff
dedicated the second Concerto to Dahl.&lt;/p&gt;

&lt;p&gt;To say I really enjoyed the play would be a slight understatement. One
of the actors was at a grand piano in center stage. He played pieces
that came up in dialogue, as well as snatches of themes from Piano
Concerto № 2 as the composer worked through his block. I experienced
&lt;a href=&quot;http://www.bbc.com/future/story/20150721-when-was-the-last-time-music-gave-you-a-skin-orgasm&quot;&gt;musical frisson—or ‘skin orgasm’—&lt;/a&gt;several times; I hadn’t
listened to any Rachmaninoff in a good while, but he is way up on my
list of favourite composers. The C♯ minor and G minor preludes, both of
which I love, were played in full.&lt;/p&gt;

&lt;p&gt;Musical performances aside, there was plenty of food for thought.
Creativity, performance anxiety, writer’s block, depression, a need to
be ‘great’, obsession with how others perceive you and your work—all too
familiar! I wish I’d had a notebook out to jot down some quotes to think
over more, especially as I come to the last three weeks at the Recurse
Center. I’ve not written here in about two weeks, and some of that is
not feeling like I have something worthy of writing about. And the
longer I go without writing, the more important it seems for the next
writing to be, if not great, at least good. I hope the play will snap me
out of that. Let’s see!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks to David Albert for telling me about the play, and to the fellow
recursers who joined me at the play.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 26 Jul 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/07/26/preludes/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/07/26/preludes/</guid>
        
        
      </item>
    
      <item>
        <title>Recurse Center lab notes 2015-07-15: X.509 PKI</title>
        <description>&lt;p&gt;I spent today working towards my Kubernetes cluster. On the way, I decided I
wanted to have client certificates to control access to the API server.&lt;/p&gt;

&lt;p&gt;Here’s an overview of where I’m going:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;generate a root certificate and key, ideally stored offline and in a hardware
security module (HSM)&lt;/li&gt;
  &lt;li&gt;use that to sign an intermediate root certificate&lt;/li&gt;
  &lt;li&gt;use the intermediate root to sign any client or server certificates&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’m just tinkering for now, and so I’m storing the root certificate on my
laptop. I’m using easy-rsa to generate the setup. It’s a collection of
scripts from the OpenVPN project to help set up a CA to use for VPN
authentication.&lt;/p&gt;

&lt;p&gt;I’m roughly following these guides, and doing peripheral reading up on what I’m
actually doing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://openvpn.net/index.php/open-source/documentation/miscellaneous/77-rsa-key-management.html&quot;&gt;https://openvpn.net/index.php/open-source/documentation/miscellaneous/77-rsa-key-management.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://wiki.archlinux.org/index.php/Create_a_Public_Key_Infrastructure_Using_the_easy-rsa_Scripts&quot;&gt;https://wiki.archlinux.org/index.php/Create_a_Public_Key_Infrastructure_Using_the_easy-rsa_Scripts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A fun part is I get to name my CA. I went with ‘Kamal Marhubi CA’, but I’m
probably going to redo it. I also have to get a better handle on all these &lt;code&gt;O&lt;/code&gt;,
&lt;code&gt;CN&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, and other fields that show up in an X.509 certificate, and what’s
allowed there. &lt;a href=&quot;https://tools.ietf.org/html/rfc5280&quot;&gt;RFC 5280&lt;/a&gt; is my friend here.&lt;/p&gt;

&lt;p&gt;Once done, I’ll have to keep running these scipts whenever I need new
certificates. That’s just fine for my small use case! I’ll need a server
certificate for each of the API server nodes, client certificates for each
worker node, and a client certificate for me to connect to the API server.&lt;/p&gt;

&lt;p&gt;If you want to get fancy, CloudFlare have &lt;a href=&quot;https://blog.cloudflare.com/how-to-build-your-own-public-key-infrastructure/&quot;&gt;a good post on setting up fancier
PKI&lt;/a&gt; using their &lt;a href=&quot;https://blog.cloudflare.com/how-to-build-your-own-public-key-infrastructure/&quot;&gt;CFSSL&lt;/a&gt; project. It includes an API server that can
issue certificates automatically.  This would be useful if you wanted your
services to be authenticated, but also to be able to spin new instances up and
down dynamically.&lt;/p&gt;

&lt;p&gt;The CloudFlare post talks about using multiple intermediate roots for different
services. The example is that an API server only trusts certificates signed by
the DB root CA, and vice versa. A comment there mentions using &lt;a href=&quot;https://tools.ietf.org/html/rfc5280#section-4.2.1.12&quot;&gt;Extended Key
Usage (EKU)&lt;/a&gt; instead. This is a standard way to designate the type of use
a certificate is valid for. This requires an OID. For external use, you’d have
to register one. But in this use case, you can use aUUID based OID. Some more
info for my future self: &lt;a href=&quot;http://www.itu.int/en/ITU-T/asn1/Pages/UUID/uuids.aspx&quot;&gt;one&lt;/a&gt;, &lt;a href=&quot;http://www.oid-info.com/get/2.25&quot;&gt;two&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For maximal fanciness, you want to be using HSMs and TPMs where possible. Both
are special hardware that stores keys, and is able to do cryptographic
operations without the key ever leaving the device. You probably have a TPM in
the computer you’re using right now, though it might be disabled. I enabled
mine in the BIOS setup, and have ‘taken ownership’ of it. As in, I literally
ran a command called &lt;code&gt;tpm_takeownership&lt;/code&gt;. I’m going to see if I can get it
added as a security device in Firefox. That way, when the time comes, I’ll be
able to store my client certificates in there. Or something!&lt;/p&gt;
</description>
        <pubDate>Wed, 15 Jul 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015-07-15/recurse-center-lab-notes</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015-07-15/recurse-center-lab-notes</guid>
        
        
      </item>
    
      <item>
        <title>Rethinking my rules</title>
        <description>&lt;p&gt;After a conversation with &lt;a href=&quot;http://jvns.ca/&quot;&gt;Julia&lt;/a&gt; and &lt;a href=&quot;https://blog.gregbrockman.com/&quot;&gt;Greg&lt;/a&gt; about how to approach the
Recurse Center, I’m revisiting my not-at-RC project list. I wrote about
this early on in &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/06/02/goals-non-goals-and-anti-goals/&quot;&gt;Goals, non-goals, and anti-goals&lt;/a&gt;. The
gist of it is that I wanted to avoid spending time on things that were
mostly ‘busywork and configuration’. The list of not-at-RC projects was
vaguely:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;, &lt;a href=&quot;https://coreos.com/&quot;&gt;CoreOS&lt;/a&gt;, and other containery and clustery stuff&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://bazel.io/&quot;&gt;Bazel&lt;/a&gt;, Google’s recently open sourced build tool&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://kythe.io/&quot;&gt;Kythe&lt;/a&gt;, Google’s recently open sourced source code indexer&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://prometheus.io/&quot;&gt;Prometheus&lt;/a&gt;, a monitoring and alerting system&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There’s a common thread here of wanting a Google-away-from-Google, at
least in terms of the developer experience. This might be misguided,
because not all problems are Google-sized. The developer experience of a
great code search, unified build system, and cluster scheduler is really
great though! The main problem is I’m not sure how many of these things
require scale to be worthwhile.&lt;/p&gt;

&lt;p&gt;Back to the conversation that made me think of changing my rules. Greg
said it was valuable to explore and learn to use tools to give you a
better understanding of how to judge similar things. That resonated with
me: if I want to have informed opinions on things in this space, I have
to use some of them!&lt;/p&gt;

&lt;p&gt;With all that in mind, here’s what I’m working on at the moment:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;fixed an issue I’d been having with my CoreOS cluster, so that I no longer
get complaints about failed systemd units on login&lt;/li&gt;
  &lt;li&gt;reading up on what’s changed in Kubernetes since I read the original design
docs when it was first released. There’s a lot of new concepts in there now,
and they’re &lt;a href=&quot;http://kuberneteslaunch.com/&quot;&gt;gearing up for a 1.0 next week&lt;/a&gt;&lt;sup id=&quot;fnref:launch-site&quot;&gt;&lt;a href=&quot;#fn:launch-site&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;,
so this seems like a good time to dig in!&lt;/li&gt;
  &lt;li&gt;I installed &lt;a href=&quot;https://sandstorm.io/&quot;&gt;Sandstorm&lt;/a&gt; on a new server in GCE. Eventually I plan to move
this to the Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Of course, bringing in a new theme means something has to go to make room. I’m
probably going to drop the priority on learning JavaScript / ES15. Unlike with
the systems programming I was doing, I don’t have a strong and clear goal in
mind there. I do expect to get back to &lt;code&gt;mmap&lt;/code&gt; and my other friends in that
world though. I’ll treat Kubernetes and CoreOS as a little break for now, and
then figure out a way to interleave the different kinds of work.&lt;/p&gt;

&lt;p&gt;This should be fun!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:launch-site&quot;&gt;

      &lt;p&gt;Yes, apparently they got a domain just for the launch. &lt;a href=&quot;#fnref:launch-site&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 14 Jul 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/07/14/rethinking-my-rules</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/07/14/rethinking-my-rules</guid>
        
        
      </item>
    
      <item>
        <title>Recurse Center lab notes 2015-07-08</title>
        <description>&lt;p&gt;Yesterday’s tinkering with Bazel and Kythe seeped into today. I attempted to
run Kythe’s indexers on its own code base. This was a multi-stage process that
took something like 15 hours of CPU time and generated 90+ GB of intermediate
data. The end result was disappointing: I get a 500 error in the provided web
service.&lt;/p&gt;

&lt;p&gt;It was definitely fun to use Blaze / Bazel again though! While Kythe didn’t
work out, I’m vaguely tempted to use Bazel on some personal stuff, but it needs
more build rules before that becomes non-painful. I need to take a slightly
closer look at what is available already. It looked like someone was adding
build rules for Rust…&lt;/p&gt;

&lt;p&gt;The rest of the day was taken up by being non-productive, followed by doing
some more ES6, followed by napping for too long. We’ll try again tomorrow!&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Jul 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/07/08/recurse-center-lab-notes</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/07/08/recurse-center-lab-notes</guid>
        
        
      </item>
    
      <item>
        <title>Recurse Center lab notes 2015-07-07: back to mmap; other people&#39;s code; things I&#39;m not meant to do while at RC</title>
        <description>&lt;p&gt;I went back to &lt;code&gt;mmap&lt;/code&gt; today. I am finally attempting to put together what I
picked up from experimenting in the last while towards writing a memory mapped
file message builder for Cap’n Proto. Current status:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I’ve created a new class with a constructor &lt;code&gt;MmapMessageBuilder(int
fd)&lt;/code&gt; that maps the file descriptor&lt;/li&gt;
  &lt;li&gt;Things mostly magically work because I’m supplying an alternate
implementation of an interface&lt;/li&gt;
  &lt;li&gt;I am not yet handling the resizing of the backing file in any way&lt;/li&gt;
  &lt;li&gt;I am not yet including a segment table at the front of the file&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The last one means I can’t get the files read back in with the existing
deserializers. I was totally able to see it in the bytes though!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;00000000  00 00 00 00 00 00 01 00  01 00 00 00 57 00 00 00  |............W...|
00000010  08 00 00 00 01 00 04 00  7b 00 00 00 02 00 00 00  |........{.......|
00000020  21 00 00 00 32 00 00 00  21 00 00 00 92 00 00 00  |!...2...!.......|
00000030  29 00 00 00 17 00 00 00  39 00 00 00 22 00 00 00  |).......9...&quot;...|
00000040  c8 01 00 00 00 00 00 00  35 00 00 00 22 00 00 00  |........5...&quot;...|
00000050  35 00 00 00 82 00 00 00  39 00 00 00 27 00 00 00  |5.......9...&#39;...|
00000060  00 00 00 00 00 00 00 00  41 6c 69 63 65 00 00 00  |........Alice...|
00000070  61 6c 69 63 65 40 65 78  61 6d 70 6c 65 2e 63 6f  |alice@example.co|
00000080  6d 00 00 00 00 00 00 00  04 00 00 00 01 00 01 00  |m...............|
00000090  00 00 00 00 00 00 00 00  01 00 00 00 4a 00 00 00  |............J...|
000000a0  35 35 35 2d 31 32 31 32  00 00 00 00 00 00 00 00  |555-1212........|
000000b0  4d 49 54 00 00 00 00 00  42 6f 62 00 00 00 00 00  |MIT.....Bob.....|
000000c0  62 6f 62 40 65 78 61 6d  70 6c 65 2e 63 6f 6d 00  |bob@example.com.|
000000d0  08 00 00 00 01 00 01 00  01 00 00 00 00 00 00 00  |................|
000000e0  09 00 00 00 4a 00 00 00  02 00 00 00 00 00 00 00  |....J...........|
000000f0  09 00 00 00 4a 00 00 00  35 35 35 2d 34 35 36 37  |....J...555-4567|
00000100  00 00 00 00 00 00 00 00  35 35 35 2d 37 36 35 34  |........555-7654|
00000110  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
00001000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Writing out the segment table mostly requires trawling through someone else’s
code base. The Cap’n Proto code is fairly clear and well documented, especially
the user interfaces. Some key innards are not as well documented, however. In
particular, the &lt;a href=&quot;https://github.com/sandstorm-io/capnproto/blob/1702050903e1038acf0556c6eabcf8f99702690d/c%2B%2B/src/capnp/arena.h#L197&quot;&gt;arena abstraction&lt;/a&gt; used to look after the
allocated segments could do with a short overview. I’m most of the way to
understanding how it fits together, but it’s been slower than I would have
liked.&lt;/p&gt;

&lt;p&gt;The process of understanding the code has been slowed by needing to learn the
&lt;a href=&quot;https://github.com/sandstorm-io/capnproto/tree/master/c%2B%2B/src/kj&quot;&gt;&lt;code&gt;kj&lt;/code&gt;&lt;/a&gt; library that Cap’n Proto makes heavy use of. I’m trying to find out
the boundaries of what &lt;code&gt;kj&lt;/code&gt; aims to be, but so far it looks to include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;replacements for some standard library classes, eg, &lt;a href=&quot;https://github.com/sandstorm-io/capnproto/blob/1702050903e1038acf0556c6eabcf8f99702690d/c%2B%2B/src/kj/memory.h#L99&quot;&gt;&lt;code&gt;kj::Own&lt;/code&gt;&lt;/a&gt;
is used where you might use&lt;a href=&quot;http://en.cppreference.com/w/cpp/memory/unique_ptr&quot;&gt; &lt;code&gt;std::unique_ptr&lt;/code&gt;&lt;/a&gt;, and
there is a separate &lt;a href=&quot;https://github.com/sandstorm-io/capnproto/blob/master/c%2B%2B/src/kj/io.h&quot;&gt;stream abstraction&lt;/a&gt; that is used instead of
&lt;a href=&quot;http://en.cppreference.com/w/cpp/io&quot;&gt;the standard one&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;an event loop—the C++ standard library still has nothing here; it may
in 2017 though!&lt;/li&gt;
  &lt;li&gt;some templated array classes that seem to be a pointer-length pair;
there is some macro magic to allow allocating such an array on the
stack&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An overview of this library would also be really nice to have. My life
would be a bit easier if this was all STL stuff.&lt;/p&gt;

&lt;p&gt;All this frustration has me trying to use Google’s &lt;a href=&quot;http://www.kythe.io/&quot;&gt;Kythe code indexing
project&lt;/a&gt; on Cap’n Proto. This in turn has me messing around with their
&lt;a href=&quot;http://bazel.io/&quot;&gt;Bazel build tool&lt;/a&gt;.  Both of these tools are up there on my
not-while-at-RC list, but I’m giving myself a very short pass to see if I can
port the build over.  Building these tools is pretty slow going…&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;current status: waiting for llvm to compile :/&lt;/p&gt;&amp;mdash; Kamal Marhubi (@kamalmarhubi) &lt;a href=&quot;https://twitter.com/kamalmarhubi/status/618613903593996289&quot;&gt;July 8, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

</description>
        <pubDate>Tue, 07 Jul 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/07/07/recurse-center-lab-notes</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/07/07/recurse-center-lab-notes</guid>
        
        
      </item>
    
      <item>
        <title>Recurse Center lab notes 2015-07-06: new Recursers, ES15, planning</title>
        <description>&lt;p&gt;Today was day one of the Summer 2 batch, meaning we got thirty new people! This
also means we had our first day without the Spring 2 batch, who I’ll definitely
miss. But several of them showed up for a games night so it’s almost like
they’re still here.&lt;/p&gt;

&lt;p&gt;It was interesting to see the intro talks again from six weeks in. A bit of
deja vu, and a good point to really stop and reflect. The advice from
the faculty was different the second time, even though the words were the same.
Our batch also gave advice or other thoughts to the new Recursers—Sophie
&lt;a href=&quot;https://sfrapoport.github.io/2015/07/06/Advice-for-Summer-2s.html&quot;&gt;jotted it all down&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ecmascript-15&quot;&gt;EcmaScript 15&lt;/h2&gt;

&lt;p&gt;The morning was taken up with welcoming the new batch, so it was a while until
I got back to programming. I decided to start learning JavaScript / ES15 with
[es6katas][]. There’s a lot of interdependence between the exercises! I started
off with the Arrays collection, but had to take a detour into destructuring. I
should have also taken a detour into iterables, as I wasn’t clear on what an
ES15 iterator was, and it was needed.&lt;/p&gt;

&lt;p&gt;So far ES15 looks pretty nice! I’m almost glad I put off learning JS for so
long. Destructuring is especially good. It’s similar to Python, but a bit more
versatile. The big features I noticed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;fields of objects can be destructured like so:&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;let dessert = { name: &quot;eton mess&quot;, tasty: true };
let {name} = dessert;
console.log(name);  // =&amp;gt; &quot;eton mess&quot;
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;It was a bit mysterious to me at first, but this also applies to fields on
builtin types, eg, &lt;code&gt;length&lt;/code&gt; on &lt;code&gt;String&lt;/code&gt;:&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;let a = &quot;hi&quot;;
let {length} = a;
console.log(length);  // =&amp;gt; 2
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;(I just realised I should check if this works for properties with getters or
 not.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;you can choose a name to bind to different from the attribute name with a
colon, eg,&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;let a = &quot;hi&quot;;
let {length:l} = a;
console.log(l);  // =&amp;gt; 2
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;you can supply defaults when destructuring which is cool! It works when you
use the default name for a binding, as well as when you change it, eg,&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;let dessert = { name: &quot;eton mess&quot;, tasty: true };
let {dairyFree=false} = dessert;  // be safe and assume desserts contain dairy
console.log(dairyFree);  // =&amp;gt; false
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;all of this comes together most excellently in using destructuring on a
function argument, eg,&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;let dessert = { name: &quot;eton mess&quot;, tasty: true };
let eat = {name:n, tasty, dairyFree:df=false} =&amp;gt; {
    if (!df || !tasty) { console.log(&quot;no thanks!&quot;); return; }

    console.log(`mmm yes, I&#39;ll eat some ${n}!`);
}

eat(dessert);  // =&amp;gt; &quot;no thanks!&quot;
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;The default arguments let you have default values in a nice succinct way, and
the binding renaming lets you have nice descriptive names in the interface but
abbreviate in the implementation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;planning-the-second-half-of-rc&quot;&gt;Planning the second half of RC&lt;/h2&gt;

&lt;p&gt;Towards the end of the day, I had a worry session with Tom, one of the
facilitators. The short of it is I’m worried I’m not going to complete as many
things as I want to. I’ve been getting a fair amount of stuff done, but aside
from &lt;a href=&quot;https://github.com/kamalmarhubi/lsaddr/&quot;&gt;&lt;code&gt;lsaddr&lt;/code&gt;&lt;/a&gt; I haven’t got much to show for it. While at RC I want
to get more comfortable completing things.&lt;/p&gt;

&lt;p&gt;Part of this is being afraid of spending too much time on a project that ends
up being too big for RC. Of course, at the other end of this, I’m also afraid
of spending too much of my time flitting between things. We ended up at the
idea of spending a solid day on each of 2-3 projects I have in mind to see
where I can get them.&lt;/p&gt;

&lt;p&gt;So, my plan for tomorrow is to take &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/06/24/recurse-center-lab-notes/&quot;&gt;what I’ve learned about &lt;code&gt;mmap&lt;/code&gt;&lt;/a&gt; and start
putting it into a Cap’n Proto message builder that writes directly to a memory
mapped file. Wish me luck!&lt;/p&gt;

</description>
        <pubDate>Mon, 06 Jul 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/07/06/recurse-center-lab-notes</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/07/06/recurse-center-lab-notes</guid>
        
        
      </item>
    
      <item>
        <title>My favourite bug so far at the Recurse Center!</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://kamalmarhubi.com/blog/2015/06/29/recurse-center-lab-notes/#python-shell-writing-weirdness&quot;&gt;Yesterday’s shell weirdness mystery&lt;/a&gt;: solved! This was definitely my favourite
bug so far here at &lt;a href=&quot;https://www.recurse.com/&quot;&gt;RC&lt;/a&gt;, so it gets its own post!&lt;/p&gt;

&lt;p&gt;As a quick recap, &lt;a href=&quot;http://sfrapoport.github.io/&quot;&gt;Sophie&lt;/a&gt; and I were trying to get pipes to work in the shell
she was writing in Python. We ended up in a situation where &lt;code&gt;ls | head&lt;/code&gt; and &lt;code&gt;ls
| wc&lt;/code&gt; worked, but &lt;code&gt;yes | head&lt;/code&gt; did not. &lt;code&gt;head&lt;/code&gt; would terminate just fine, and
only ten lines of &lt;code&gt;y&lt;/code&gt; were printed, but &lt;code&gt;yes&lt;/code&gt; continued to run and consume lots
of CPU.&lt;/p&gt;

&lt;p&gt;Oh, and this happened on Sophie’s OS X machine, but not on my Linux one. Both were
running Python 2.7.10.&lt;/p&gt;

&lt;p&gt;To break this down a bit more, we’ve got four commands we’re dealing with: two
which produce data on standard output—&lt;code&gt;ls&lt;/code&gt; and &lt;code&gt;yes&lt;/code&gt;—and two which consume
data on standard input—&lt;code&gt;wc&lt;/code&gt; and &lt;code&gt;head&lt;/code&gt; &lt;sup id=&quot;fnref:wc-head-stdout&quot;&gt;&lt;a href=&quot;#fn:wc-head-stdout&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. We can divide these
by whether they produce or consume a bounded or unbounded amount of data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;producers
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;ls&lt;/code&gt;: bounded&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;yes&lt;/code&gt;: unbounded&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;consumers:
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;head&lt;/code&gt;: bounded&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;wc&lt;/code&gt;: unbounded&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now let’s look at the pipelines we were running again:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;producer&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;consumer&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code&gt;ls | head&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;bounded&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;bounded&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code&gt;ls | wc&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;bounded&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;unbounded&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code&gt;yes | head&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;unbounded&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;bounded&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Our issue comes up when we have an unbounded producer with a bounded consumer.
But only on OS X.&lt;/p&gt;

&lt;p&gt;So now we’re all caught up, here’s what happened today. Sophie messaged me this
morning saying:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I think I found something that will help us:
&lt;a href=&quot;http://www.chiark.greenend.org.uk/~cjwatson/blog/python-sigpipe.html&quot;&gt;http://www.chiark.greenend.org.uk/~cjwatson/blog/python-sigpipe.html&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;PS: I wouldn’t have found this if you hadn’t mentioned exploring SIGPIPE in
your blog post. I read about it and said, ‘I think we have a problem with
SIGPIPE on OSX/Python!’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I &lt;em&gt;love&lt;/em&gt; this because that wasn’t in the part of the post about our shell bug:
it was just pure coincidence!&lt;/p&gt;

&lt;p&gt;That page links to a &lt;a href=&quot;http://bugs.python.org/issue1615376&quot;&gt;bug against Python 3.2&lt;/a&gt;. She did some further
investigation and turned up a &lt;a href=&quot;http://bugs.python.org/issue1652&quot;&gt;bug against Python 2.7&lt;/a&gt; about this.
Sadly, this was closed as wontfix ‘because it is too late to backport this to 2.7.’&lt;/p&gt;

&lt;p&gt;The gist of the bugs is this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Python sets the disposition for &lt;code&gt;SIGPIPE&lt;/code&gt; to ignore, and instead checks the
return value of all its writes for errors; this allows raising exceptions in
Python code instead of requiring installation of a signal handler&lt;/li&gt;
  &lt;li&gt;signal dispositions and handlers are inherited by the child after &lt;code&gt;fork&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;execve&lt;/code&gt; resets signals with handlers to their default dispositions;
otherwise it leaves their dispositions alone&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This results in a process &lt;code&gt;execve&lt;/code&gt;‘d from Python starting off ignoring
&lt;code&gt;SIGPIPE&lt;/code&gt;. Unless it resets its signal dispositions to the default, it will
receive errors instead of signals on writes to broken pipes. There are a couple
of fixes suggested in the bugs, but neither are applied in Python 2.7. Our
shell launches programs which ignore &lt;code&gt;SIGPIPE&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We’re getting closer!  All this sounds great, but it doesn’t explain the
works-on-Linux-but-not-on-OS X part. This is where it gets really fun. To quote
myself, just a few sentences ago: ‘Python sets the disposition for &lt;code&gt;SIGPIPE&lt;/code&gt; to
ignore, and &lt;em&gt;instead checks the return value of all its writes for errors&lt;/em&gt;’.
That last part is really important.&lt;/p&gt;

&lt;p&gt;At this point we realised we needed to check what &lt;code&gt;yes&lt;/code&gt; was actually doing. The
version on my machine comes from GNU coreutils. We can take a look at &lt;a href=&quot;https://sources.debian.net/src/coreutils/8.23-4/src/yes.c/#L80&quot;&gt;the loop
where it writes its output&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;  while (true)
    {
      int i;
      for (i = optind; i &amp;lt; argc; i++)
        if (fputs (argv[i], stdout) == EOF
            || putchar (i == argc - 1 ? &#39;\n&#39; : &#39; &#39;) == EOF)
          error (EXIT_FAILURE, errno, _(&quot;standard output&quot;));
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Look at all that error checking! From &lt;a href=&quot;http://man7.org/linux/man-pages/man3/puts.3.html#RETURN_VALUE&quot;&gt;&lt;code&gt;man 3 puts&lt;/code&gt;&lt;/a&gt;, which
covers both &lt;code&gt;fputs&lt;/code&gt; and &lt;code&gt;putchar&lt;/code&gt;, we can see that they return &lt;code&gt;EOF&lt;/code&gt; on error;
and &lt;a href=&quot;http://man7.org/linux/man-pages/man3/error.3.html&quot;&gt;&lt;code&gt;error(3)&lt;/code&gt;&lt;/a&gt; prints out a nice error message.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://www.opensource.apple.com/source/shell_cmds/shell_cmds-170/yes/yes.c&quot;&gt;implementation of &lt;code&gt;yes&lt;/code&gt; on OS X&lt;/a&gt; is short enough that I can excerpt its entire &lt;code&gt;main&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;int
main(argc, argv)
    int argc;
    char **argv;
{
    if (argc &amp;gt; 1)
        for(;;)
            (void)puts(argv[1]);
    else for (;;)
        (void)puts(&quot;y&quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Look at those unchecked calls to &lt;code&gt;puts&lt;/code&gt;! At last we have our answer! And to be
sure, I compiled the OS X version on my machine, and we got the same behaviour!
Mystery solved!&lt;/p&gt;

&lt;p&gt;I love this bug for so many reasons. In particular, I love that it involves so
many parties. There’s the Python bug. There’s the OS X &lt;code&gt;yes&lt;/code&gt; implementation
that doesn’t check its &lt;code&gt;puts&lt;/code&gt; calls’ return values. And it shouldn’t have to
for the pipe case since it can reasonably expect &lt;code&gt;SIGPIPE&lt;/code&gt; to have its default
action of terminating the process. Where this got confusing is that the GNU
implementation &lt;em&gt;does&lt;/em&gt; check for errors, so we got the OS difference. If Sophie
had been using Linux, we never would have encountered this!&lt;/p&gt;

&lt;p&gt;A big takeaway for me here is that it’s up to us as developers to deal with
idiosyncrasies in our platform. The fact that there’s an acknowledged bug in
Python doesn’t mean we can just throw up our hands in a big ¯\_(ツ)_/¯.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:wc-head-stdout&quot;&gt;

      &lt;p&gt;&lt;code&gt;wc&lt;/code&gt; and &lt;code&gt;head&lt;/code&gt; both also produce data on standard output, but only in
response to data on standard input; this isn’t interesting because of which
side of the pipe we put them on &lt;a href=&quot;#fnref:wc-head-stdout&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 30 Jun 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/06/30/my-favourite-bug-so-far-at-the-recurse-center/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/06/30/my-favourite-bug-so-far-at-the-recurse-center/</guid>
        
        
      </item>
    
  </channel>
</rss>
