<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kamal Marhubi</title>
    <description></description>
    <link>http://kamalmarhubi.com/</link>
    <atom:link href="http://kamalmarhubi.com/blog/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 09 Feb 2016 22:08:02 -0500</pubDate>
    <lastBuildDate>Tue, 09 Feb 2016 22:08:02 -0500</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>100:10:1 update 2</title>
        <description>&lt;p&gt;I’m still being slow on picking the 10, but I’ve added a new one to the list. It
now stands at two items!&lt;/p&gt;

&lt;h2 id=&quot;a-very-silly-key-value-store&quot;&gt;A very silly key-value store&lt;/h2&gt;
&lt;p&gt;I’m really excited about the new idea. It’s a very silly key-value store. The
exact nature of the silliness will wait until I’m further along. I’ll make it
speak either the memcached or redis protocol—or both! This makes it fit under
one or both of these items from the &lt;a href=&quot;http://kamalmarhubi.com/blog/2016/01/25/100-10-1/&quot;&gt;original 100&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;memcached speaking thing&lt;/li&gt;
  &lt;li&gt;redis speaking thing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’ll be doing this in Rust—naturally. As a bit of preparation, I’ve already added
&lt;a href=&quot;https://github.com/rust-lang-nursery/libc/pull/170&quot;&gt;&lt;code&gt;sendfile(2)&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/rust-lang-nursery/libc/pull/172&quot;&gt;&lt;code&gt;splice(2)&lt;/code&gt;, &lt;code&gt;tee(2)&lt;/code&gt;, and
&lt;code&gt;vmsplice(2)&lt;/code&gt;&lt;/a&gt; to the libc crate, and am working on adding them to
&lt;a href=&quot;https://github.com/carllerche/nix-rust&quot;&gt;nix&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once that’s done, I should be able to start on the silly part! :-)&lt;/p&gt;

&lt;h2 id=&quot;rustfmt-diff-formatting&quot;&gt;rustfmt diff formatting&lt;/h2&gt;
&lt;p&gt;I finally got &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/pull/812&quot;&gt;a pull request&lt;/a&gt; tidying up some config stuff
merged. This was neither my &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/pull/795&quot;&gt;first attempt&lt;/a&gt; nor my &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/pull/801&quot;&gt;second
attempt&lt;/a&gt;, but it got there eventually!&lt;/p&gt;

&lt;p&gt;I’ve exhausted what I’ve decided was some &lt;a href=&quot;http://composition.al/blog/2015/12/29/refactoring-as-a-way-to-understand-code/&quot;&gt;refactoring as a way to understand
code&lt;/a&gt;, but have not made a start on the actual task quite yet. I’m
working on a couple of other Rust developer infrastructure kinds of projects in
the meantime, but should get on with this one. I &lt;em&gt;really&lt;/em&gt; want to be able to
run &lt;code&gt;cargo fmt-diff&lt;/code&gt; or whatever the command ends up being.&lt;/p&gt;

</description>
        <pubDate>Tue, 09 Feb 2016 22:04:15 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2016/02/09/100-10-1-update-2/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2016/02/09/100-10-1-update-2/</guid>
        
        
      </item>
    
      <item>
        <title>100:10:1 update 1</title>
        <description>&lt;p&gt;I’m going to try and write little updates as I work on &lt;a href=&quot;http://kamalmarhubi.com/blog/2016/01/25/100-10-1/&quot;&gt;100:10:1&lt;/a&gt;.
Here’s the first!&lt;/p&gt;

&lt;h1 id=&quot;picking-1-of-the-10&quot;&gt;Picking 1 of the 10&lt;/h1&gt;

&lt;p&gt;I haven’t made my short list of 10 prototypes quite yet, but I have picked one
of them. Loads of the projects I’m thinking of are in Rust, so I’m preemptively
shaving a yak and working on making the &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt&quot;&gt;rustfmt&lt;/a&gt; formatting tool work
incrementally. This was in the original list of 100 as&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;rustfmt line range &amp;amp; diff reading (format a patch)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Translating from Kamal-scribble-speak: make it so that rustfmt can format only a
specific set of lines. Then on top of that, make it format only the lines that
have changed according to a diff. This way you can always run rustfmt, safe in
the knowledge that it won’t be sticking all kinds of style changes across the
codebase along with your actual changes. It should even be possible to put it in
a pre-commit hook.&lt;/p&gt;

&lt;p&gt;I actually &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/issues/434&quot;&gt;filed an issue&lt;/a&gt; about this back in October, and even started
trying to work on it. It turns out it’s really hard to implement something
non-trivial in a codebase you’re unfamiliar with in a language you don’t know.&lt;/p&gt;

&lt;p&gt;But I’ve been doing some Rust since then, including working on &lt;a href=&quot;https://github.com/rust-lang/rust/pull/31056&quot;&gt;a patch to the
standard library&lt;/a&gt;. I’m way more fluent now, though there are still some
bits of the Rust library and type system I need to absorb further.&lt;/p&gt;

&lt;p&gt;Working myself up to the line ranges change, I’ve put &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/pulls?utf8=%E2%9C%93&amp;amp;q=is%3Apr+author%3Akamalmarhubi+created%3A2016-01-31..2016-02-02&quot;&gt;a bunch of improvements
out&lt;/a&gt;, mostly small. The big one was unifying the config object that
is passed through all parts of the formatting process. This will give me a place
to store the line ranges to be formatted. I’m waiting on &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/pull/801&quot;&gt;the
review&lt;/a&gt; for it:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;tfw you want someone to review your code from 5 hours ago but they are in new zealand&lt;/p&gt;&amp;mdash; Kamal Marhubi (@kamalmarhubi) &lt;a href=&quot;https://twitter.com/kamalmarhubi/status/694639801765527552&quot;&gt;February 2, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;up-next&quot;&gt;Up next&lt;/h1&gt;

&lt;p&gt;Actually implement the thing! I’ll probably write up some notes as I do this.
I’m pretty glad to have picked this project because it involves getting to know
a bit about how the Rust &lt;abbr title=&quot;abstract syntax tree&quot;&gt;AST&lt;/abbr&gt; is organized.&lt;/p&gt;

&lt;p&gt;rustfmt is an &lt;abbr title=&quot;abstract syntax tree&quot;&gt;AST&lt;/abbr&gt;-based formatter, rather than a token-based one. Instead of
moving bits of text around, it actually parses the entire program, and then
pretty prints it according to style rules. There’s &lt;a href=&quot;https://github.com/rust-lang-nursery/rustfmt/blob/master/Design.md&quot;&gt;a brief outline of the
design&lt;/a&gt; that’s pretty good if you want to read about it.&lt;/p&gt;

&lt;p&gt;For my change, the line ranges need to be translated to a set of &lt;abbr title=&quot;abstract syntax tree&quot;&gt;AST&lt;/abbr&gt; nodes, and
then selectively formatted. There will be some niggles around sets of lines that
straddle node boundaries which I’ll have to think about. And maybe even draw
some ‘pictures’!&lt;/p&gt;

</description>
        <pubDate>Tue, 02 Feb 2016 22:46:25 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2016/02/02/100-10-1-update-1/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2016/02/02/100-10-1-update-1/</guid>
        
        
      </item>
    
      <item>
        <title>Eat your greens and read your man pages</title>
        <description>&lt;p&gt;I’ve been working on a little tool to let unprivileged users run commands in
the context of a container image’s filesystem on Linux.  I’m really bad at
names, so let’s call it &lt;code&gt;containy-thing&lt;/code&gt;. That also evokes about the right
level of completeness: it’s quite far from done.&lt;/p&gt;

&lt;p&gt;Anyway, this is a little field report from working on it. Its moral is: read
your man pages.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;containy-thing&lt;/code&gt; uses a few Linux tricks to do its job, the main ones being
&lt;a href=&quot;http://man7.org/linux/man-pages/man7/user_namespaces.7.html&quot;&gt;user&lt;/a&gt; and mount &lt;a href=&quot;http://man7.org/linux/man-pages/man7/namespaces.7.html&quot;&gt;namespaces&lt;/a&gt;. It takes a directory to use as the
container root filesystem, and a command to run, and runs the command. If
you’ve used docker,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ containy-thing /path/to/rootfs /bin/ls -l
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;would be similar to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# docker run my-image /bin/ls -l
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Note the &lt;code&gt;$&lt;/code&gt; vs &lt;code&gt;#&lt;/code&gt; prompts! The main point of this project is that you can
run it as an unprivileged user; docker needs superuser privileges.)&lt;/p&gt;

&lt;p&gt;I was trying to test it out and had an extracted root filesystem for an
Ubuntu-derived image. I attempted to run &lt;code&gt;/bin/ls -l&lt;/code&gt;, but it kept failing.
Investigating a bit, I found that the &lt;code&gt;execve(2)&lt;/code&gt; system call to start
&lt;code&gt;/bin/ls&lt;/code&gt; was failing with &lt;code&gt;EACCES&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;read-your-man-pages&quot;&gt;read your man pages&lt;/h1&gt;

&lt;p&gt;I’ve done bits and pieces of systems programming, and the man pages are pretty
great most of the time. The man page for &lt;a href=&quot;http://man7.org/linux/man-pages/man2/execve.2.html#ERRORS&quot;&gt;&lt;code&gt;execve(2)&lt;/code&gt;&lt;/a&gt; definitely falls
under ‘most of the time’, and is pretty exhaustive. It lists the circumstances
that could result in &lt;code&gt;EACCES&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       EACCES Search permission is denied on a component of the path prefix of
              filename or the name of a script interpreter.  (See also
              path_resolution(7).)

       EACCES The file or a script interpreter is not a regular file.

       EACCES Execute permission is denied for the file or a script or ELF
              interpreter.

       EACCES The filesystem is mounted noexec.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I went through these one by one:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;checked that all path components (namely, &lt;code&gt;/bin&lt;/code&gt;) had the search permission
(&lt;code&gt;a+x&lt;/code&gt;) set (&lt;code&gt;/bin/ls&lt;/code&gt; is not a script, and so there was no script
interpreter to check)&lt;/li&gt;
  &lt;li&gt;checked that &lt;code&gt;/bin/ls&lt;/code&gt; was there, and was a file&lt;/li&gt;
  &lt;li&gt;checked that &lt;code&gt;/bin/ls&lt;/code&gt;/ had the execute permission (&lt;code&gt;a+x&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;double checked the mount to be sure it wasn’t &lt;code&gt;noexec&lt;/code&gt;, which disallows
execution of all files on the filesystem&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nothing came up. I did this a bunch of times, and still nothing came up.&lt;/p&gt;

&lt;h1 id=&quot;no-really-read-your-man-pages&quot;&gt;no really, read your man pages&lt;/h1&gt;

&lt;p&gt;Eventually, I finally realized what the problem was. The third reason for
&lt;code&gt;EACCES&lt;/code&gt; was&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       EACCES Execute permission is denied for the file or a script or ELF
              interpreter.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but I was reading&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       EACCES Execute permission is denied for the file or a script       
              interpreter.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I didn’t even stop to think that something could be wrong with the ELF
interpreter. I only even vaguely understand what an ELF interpreter does! But
after wasting probably a day and a bit trying to figure this out, I finally
took a look. The interpreter for x86-64 programs on Linux is at
&lt;code&gt;/lib64/ld-linux-x86-64.so.2&lt;/code&gt;, at least on Debian and Ubuntu…. and its
permissions were wrong.&lt;/p&gt;
</description>
        <pubDate>Tue, 26 Jan 2016 10:19:54 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2016/01/26/eat-your-greens-and-read-your-man-pages/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2016/01/26/eat-your-greens-and-read-your-man-pages/</guid>
        
        
      </item>
    
      <item>
        <title>100:10:1</title>
        <description>&lt;p&gt;Last week I decided to join &lt;a href=&quot;https://writing.natwelch.com/&quot;&gt;Nat&lt;/a&gt; and &lt;a href=&quot;http://redlua.com/&quot;&gt;Steve&lt;/a&gt; and make an attempt at the
100:10:1 project idea generation / implementation idea &lt;a href=&quot;https://nickbentleygames.wordpress.com/2014/05/12/the-100-10-1-method-for-game-design/&quot;&gt;Nick
Bentley&lt;/a&gt; wrote about in the context of game design, and
&lt;a href=&quot;http://blog.fogus.me/2015/11/04/the-100101-method-my-approach-to-open-source/&quot;&gt;fogus adapted to open source projects&lt;/a&gt;. It’s a three step process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;come up with 100 project ideas&lt;/li&gt;
  &lt;li&gt;build MVPs for 10 of them&lt;/li&gt;
  &lt;li&gt;develop 1 of them into a complete thing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’m playing catch up with Nat and Steve, who both have their 100 and 10 already
picked out! But I’ve got my 100 ideas together now, which are listed at the end
of this post without any organization.&lt;/p&gt;

&lt;p&gt;Some takeaways from doing this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I’m &lt;em&gt;really&lt;/em&gt; interested in lower level / infrastructure / systems stuff at
the moment&lt;/li&gt;
  &lt;li&gt;I really like Rust&lt;/li&gt;
  &lt;li&gt;I really like Kubernetes&lt;/li&gt;
  &lt;li&gt;and some other things&lt;/li&gt;
  &lt;li&gt;not much in the way of producty or goofy ideas as compared to the other two, but there you go!&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;section&quot;&gt;100&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;heroku clone on kubernetes&lt;/li&gt;
  &lt;li&gt;container thing for running commands in container context without privileges&lt;/li&gt;
  &lt;li&gt;rust high perf networking http server (techempower benchmarks, haywire)&lt;/li&gt;
  &lt;li&gt;rust async library experiments: curio, asyncio, folly, util::Task&lt;/li&gt;
  &lt;li&gt;rust ideas around cancellation for async: util::Task, golang.org/x/net/context, C# CancellationToken&lt;/li&gt;
  &lt;li&gt;rust lib to restart without dropping connections&lt;/li&gt;
  &lt;li&gt;tuf + rust + crates&lt;/li&gt;
  &lt;li&gt;kythe extractor / indexer for rust&lt;/li&gt;
  &lt;li&gt;kythe (?) based github search that doesn’t suck&lt;/li&gt;
  &lt;li&gt;kythe browser that works nice&lt;/li&gt;
  &lt;li&gt;package pageshot for sandstorm&lt;/li&gt;
  &lt;li&gt;static site generator using service worker / amp / … ?&lt;/li&gt;
  &lt;li&gt;graphiql / graphql for jsonapi&lt;/li&gt;
  &lt;li&gt;“cloud” load balancer for kubernetes&lt;/li&gt;
  &lt;li&gt;criu + cap’n proto (?) for magic on-demand lb&lt;/li&gt;
  &lt;li&gt;implement tcp/ip (in rust?)&lt;/li&gt;
  &lt;li&gt;build reliable communication on top of udp&lt;/li&gt;
  &lt;li&gt;cap’n proto shared memory transport&lt;/li&gt;
  &lt;li&gt;cap’n proto mmap message builder&lt;/li&gt;
  &lt;li&gt;figure out userfaultfd for the above&lt;/li&gt;
  &lt;li&gt;ebpf based strace&lt;/li&gt;
  &lt;li&gt;seccomp (bpf) for rust&lt;/li&gt;
  &lt;li&gt;multiprocess lib for rust&lt;/li&gt;
  &lt;li&gt;pledge clone for linux using seccomp-bpf + namespaces&lt;/li&gt;
  &lt;li&gt;extend roaring bitmap rust to handle runs&lt;/li&gt;
  &lt;li&gt;rust clap bash completions&lt;/li&gt;
  &lt;li&gt;x_things twitter bot generator – creates bot, heroku app, sends credentials&lt;/li&gt;
  &lt;li&gt;window tiny lfu (w-tinylfu) cache gh/ben-manes/caffeine/wiki/efficiency&lt;/li&gt;
  &lt;li&gt;cap’n proto compiler bootstrapping with json&lt;/li&gt;
  &lt;li&gt;debugger (500 lines)&lt;/li&gt;
  &lt;li&gt;test tool at syscall interface (ptrace / seccomp bpf?)&lt;/li&gt;
  &lt;li&gt;explore allowing overlayfs with namespace owned mounts&lt;/li&gt;
  &lt;li&gt;kubernetes + timely dataflow&lt;/li&gt;
  &lt;li&gt;rustfmt line range &amp;amp; diff reading (format a patch)&lt;/li&gt;
  &lt;li&gt;rustdoc improvements: stable since, target differences&lt;/li&gt;
  &lt;li&gt;package firefox sync for sandstorm&lt;/li&gt;
  &lt;li&gt;fuzz cap’n proto rust&lt;/li&gt;
  &lt;li&gt;AFL + quickcheck: coverage directed fuzzing for rust / testing&lt;/li&gt;
  &lt;li&gt;markdown editor with gdoc like commenting and suggesting&lt;/li&gt;
  &lt;li&gt;port rustc build to bazel&lt;/li&gt;
  &lt;li&gt;port cap’n proto build to bazel&lt;/li&gt;
  &lt;li&gt;port sandstorm build to bazel&lt;/li&gt;
  &lt;li&gt;web-based handbell ringing app&lt;/li&gt;
  &lt;li&gt;bazel docker improvements&lt;/li&gt;
  &lt;li&gt;bazel appc rules&lt;/li&gt;
  &lt;li&gt;kubernetes appc support&lt;/li&gt;
  &lt;li&gt;bazel rust rules support cross compilation&lt;/li&gt;
  &lt;li&gt;csmith for rust (generate random programs)&lt;/li&gt;
  &lt;li&gt;blue line cenerator / viewer for web&lt;/li&gt;
  &lt;li&gt;composition checker&lt;/li&gt;
  &lt;li&gt;ringing social app (a la ravelry?) with peal &amp;amp; qp reports&lt;/li&gt;
  &lt;li&gt;octopus holdings zulip bot&lt;/li&gt;
  &lt;li&gt;two corpus twitter bot generator (a la erowidrecruiter)&lt;/li&gt;
  &lt;li&gt;rust crate version vs rust language version&lt;/li&gt;
  &lt;li&gt;hybrid logical clock implementation (rust?)&lt;/li&gt;
  &lt;li&gt;impelemnt a crdt&lt;/li&gt;
  &lt;li&gt;implement a consensus protocol&lt;/li&gt;
  &lt;li&gt;create an official backport for debian – nodejs?&lt;/li&gt;
  &lt;li&gt;create an official package for debian – watchman?&lt;/li&gt;
  &lt;li&gt;egit shallow clone OR allow shallow clone via git for bazel&lt;/li&gt;
  &lt;li&gt;swagger client generator for rust&lt;/li&gt;
  &lt;li&gt;implement perfect consistent hashing arXiv:1503:04988&lt;/li&gt;
  &lt;li&gt;elevator algorithm competition site&lt;/li&gt;
  &lt;li&gt;port google research benchmark thing to rust (r/rust/comments/42fnw7)&lt;/li&gt;
  &lt;li&gt;clocks traits for rust&lt;/li&gt;
  &lt;li&gt;rust bridge project investigation – os?&lt;/li&gt;
  &lt;li&gt;rust cstring ergonomics improvements&lt;/li&gt;
  &lt;li&gt;pure rust ssh2 implementation&lt;/li&gt;
  &lt;li&gt;server side bindings for libssh2 rust&lt;/li&gt;
  &lt;li&gt;rust ci iuld for windows on appveyor&lt;/li&gt;
  &lt;li&gt;lmax disruptor implementation&lt;/li&gt;
  &lt;li&gt;implement some lock free data structures&lt;/li&gt;
  &lt;li&gt;cache friendly data structures for rust&lt;/li&gt;
  &lt;li&gt;figure out swagger &amp;amp; json api&lt;/li&gt;
  &lt;li&gt;something like scapy for network playing around but in rust&lt;/li&gt;
  &lt;li&gt;rust take on jgc’s little parallel do stuff library&lt;/li&gt;
  &lt;li&gt;memcached speaking thing&lt;/li&gt;
  &lt;li&gt;redis speaking thing&lt;/li&gt;
  &lt;li&gt;spliterator for rust (if it makes sense)&lt;/li&gt;
  &lt;li&gt;gitsync w/ray&lt;/li&gt;
  &lt;li&gt;ssh multiplexer / proxy thing (?)&lt;/li&gt;
  &lt;li&gt;custom replacement of the screen-on app thing on android with timeouts built in&lt;/li&gt;
  &lt;li&gt;hyper log log on timely dataflow&lt;/li&gt;
  &lt;li&gt;command line client for banq&lt;/li&gt;
  &lt;li&gt;command line client for tangerine&lt;/li&gt;
  &lt;li&gt;token bucket in rust&lt;/li&gt;
  &lt;li&gt;rethinkdb client in rust&lt;/li&gt;
  &lt;li&gt;rust config library using command line flags, env vars, config files (w/overriding)&lt;/li&gt;
  &lt;li&gt;SHIM tracing framework… high frequency sampling profiler&lt;/li&gt;
  &lt;li&gt;prometheus client for rust&lt;/li&gt;
  &lt;li&gt;hdr histograms for prometheus&lt;/li&gt;
  &lt;li&gt;stats / metrics for rust (gh/rust-lang/rfcs/issue/843)&lt;/li&gt;
  &lt;li&gt;fd transfer for cap’n proto&lt;/li&gt;
  &lt;li&gt;trusted build service (toto)&lt;/li&gt;
  &lt;li&gt;rust libc generator or test constants (&amp;amp; signatures?)&lt;/li&gt;
  &lt;li&gt;sites &amp;amp; mobile app that lets my family track our locations&lt;/li&gt;
  &lt;li&gt;something like the original hangouts – say you’re vailable to hangout (again, family)&lt;/li&gt;
  &lt;li&gt;tool to blas through images and highlight some picks as video&lt;/li&gt;
  &lt;li&gt;god bold rustc asm output thing (historical)&lt;/li&gt;
  &lt;li&gt;grpc for rust&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 25 Jan 2016 17:03:49 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2016/01/25/100-10-1/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2016/01/25/100-10-1/</guid>
        
        
      </item>
    
      <item>
        <title>Squashing Docker images with Btrfs</title>
        <description>&lt;p&gt;Here’s a small hack for squashing a Docker image to a single layer if you
happen to run with &lt;code&gt;/var/lib&lt;/code&gt; on a Btrfs filesystem. The output will be a tar
file you can use with &lt;a href=&quot;http://docs.docker.com/engine/reference/builder/#add&quot;&gt;&lt;code&gt;ADD&lt;/code&gt;&lt;/a&gt; in a &lt;code&gt;Dockerfile&lt;/code&gt; to create a flat
base image.&lt;/p&gt;

&lt;p&gt;This is an alternative to &lt;a href=&quot;http://docs.docker.com/engine/reference/commandline/create/&quot;&gt;&lt;code&gt;docker create&lt;/code&gt;&lt;/a&gt;-ing a container and
running &lt;a href=&quot;http://docs.docker.com/engine/reference/commandline/export/&quot;&gt;&lt;code&gt;docker export&lt;/code&gt;&lt;/a&gt; on it to get the filesystem contents.
It saves you having to &lt;a href=&quot;http://docs.docker.com/engine/reference/commandline/rm/&quot;&gt;&lt;code&gt;docker rm&lt;/code&gt;&lt;/a&gt; the container afterwards.&lt;/p&gt;

&lt;p&gt;First, get the ID of the image you want to squash:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images rethink
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
rethinkdb           latest              ffb24b60063b        6 days ago          181.8 MB
rethinkdb           2.0.4               83d2da4505dc        2 weeks ago         195.8 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I’ll go with the latest version, &lt;code&gt;ffb24b60063b&lt;/code&gt;. This is a prefix of the full
image ID. The image will be a Btrfs snapshot in
&lt;code&gt;/var/lib/docker/Btrfs/subvolumes&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo -i
# cd /var/lib/docker/btrfs/subvolumes
# ls -d ffb24b60063b*
ffb24b60063ba7e26ebf2f888deb5af0c8966dcbb612353fcd0c5d52a0a1d234
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;a href=&quot;http://docs.docker.com/engine/userguide/storagedriver/btrfs-driver/&quot;&gt;Btrfs storage driver’s documentation&lt;/a&gt; goes into a
fair bit of detail on how the driver uses Btrfs subvolumes and snapshots for
images and containers.&lt;/p&gt;

&lt;p&gt;Here’s an exerpt from &lt;a href=&quot;https://github.com/justone/dockviz&quot;&gt;&lt;code&gt;dockviz&lt;/code&gt;&lt;/a&gt; output for that image that shows the
various layers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├─1565e86129b8 Virtual Size: 125.1 MB
│ └─a604b236bcde Virtual Size: 125.1 MB Tags: debian:latest
│   └─3012d15ee771 Virtual Size: 125.1 MB
│     └─67ab878cc688 Virtual Size: 125.1 MB
│       └─d4d9554f3430 Virtual Size: 125.1 MB
│         └─d4bdd500e4ec Virtual Size: 125.1 MB
│           └─9c56aa19b706 Virtual Size: 181.8 MB
│             └─9102e5038f43 Virtual Size: 181.8 MB
│               └─c5dff5ddf6a8 Virtual Size: 181.8 MB
│                 └─769806cae856 Virtual Size: 181.8 MB
│                   └─ffb24b60063b Virtual Size: 181.8 MB Tags: rethinkdb:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then it’s just a matter of:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo -i
# cd /var/lib/docker/btrfs/subvolumes/ffb24b60063ba7e26ebf2f888deb5af0c8966dcbb612353fcd0c5d52a0a1d234
# tar c . &amp;gt; /tmp/rethink-squashed.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tab completion should pick up the full directory name from the short image ID,
so you don’t have to copy the complete ID.&lt;/p&gt;

&lt;p&gt;That’s pretty much it. You can get a flat base image with a &lt;code&gt;Dockerfile&lt;/code&gt;
with these contents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM sratch
ADD rethink-squashed.tar /
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Fri, 27 Nov 2015 14:44:03 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/11/27/squashing-docker-images-with-btrfs/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/11/27/squashing-docker-images-with-btrfs/</guid>
        
        
      </item>
    
      <item>
        <title>Using strace to figure out how git push over SSH works</title>
        <description>&lt;p&gt;Yesterday I was curious about how &lt;code&gt;git push&lt;/code&gt; works over SSH. I’m getting more
used to using &lt;code&gt;strace&lt;/code&gt; to figure this kind of thing out, so I gave it a shot.
If I &lt;code&gt;strace&lt;/code&gt; pushing to this site’s repository, this shows up:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[pid 15943] execve(&quot;/usr/bin/ssh&quot;, [&quot;ssh&quot;, &quot;git@github.com&quot;, &quot;git-receive-pack &#39;kamalmarhubi/w&quot;...], [/* 51 vars */]) = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &lt;code&gt;git push&lt;/code&gt; eventually calls &lt;code&gt;ssh git@github.com git-receive-pack &amp;lt;repo-path&amp;gt;&lt;/code&gt;.
Trying this out at my terminal gives me this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh git@github.com git-receive-pack kamalmarhubi/website
00bb29793c39c8e4bfec627d60938c4ed2086cc60bb1 refs/heads/gh-pagesreport-status delete-refs side-band-64k quiet atomic ofs-delta agent=git/2:2.4.8~upload-pack-wrapper-script-1211-gc27b061
003f04bfcb3e238e5660ae9e71a6ce99f472211fe85f refs/heads/master
0000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with the terminal waiting for my input. SSH is used to handle authentication
and remote connection, and then it runs a command at the other end to handle
the data exchange. These lines are the start of that exchange.&lt;/p&gt;

&lt;p&gt;A tiny bit of looking around the internet told me that the protocol is made up
of lines prefixed by their length as 4 hex digits. Then it looks like a commit
SHA-1 and a ref. The sender terminates with &lt;code&gt;0000&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;There are a couple of lines here, one for each branch in the repository. The
first line additionally has a bunch of stuff at the end that looks like a
description of what the sending program is and some features it supports.&lt;/p&gt;

&lt;p&gt;While I was looking into this, I used &lt;code&gt;xsel&lt;/code&gt; to copy the output to paste into
an editor. This was really confusing, because all that got pasted was the first
line without all the metadata!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;00bb29793c39c8e4bfec627d60938c4ed2086cc60bb1 refs/heads/gh-pages
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the entire output through &lt;code&gt;hexdump -C&lt;/code&gt;, it turns out that there’s a
null byte after &lt;code&gt;refs/heads/gh-pages&lt;/code&gt;, and then a newline at the end (marked with &lt;code&gt;*&lt;/code&gt; below):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;00000000  30 30 62 62 32 39 37 39  33 63 33 39 63 38 65 34  |00bb29793c39c8e4|
00000010  62 66 65 63 36 32 37 64  36 30 39 33 38 63 34 65  |bfec627d60938c4e|
00000020  64 32 30 38 36 63 63 36  30 62 62 31 20 72 65 66  |d2086cc60bb1 ref|
00000030  73 2f 68 65 61 64 73 2f  67 68 2d 70 61 67 65 73  |s/heads/gh-pages|
00000040 *00*72 65 70 6f 72 74 2d  73 74 61 74 75 73 20 64  |.report-status d|
00000050  65 6c 65 74 65 2d 72 65  66 73 20 73 69 64 65 2d  |elete-refs side-|
00000060  62 61 6e 64 2d 36 34 6b  20 71 75 69 65 74 20 61  |band-64k quiet a|
00000070  74 6f 6d 69 63 20 6f 66  73 2d 64 65 6c 74 61 20  |tomic ofs-delta |
00000080  61 67 65 6e 74 3d 67 69  74 2f 32 3a 32 2e 34 2e  |agent=git/2:2.4.|
00000090  38 7e 75 70 6c 6f 61 64  2d 70 61 63 6b 2d 77 72  |8~upload-pack-wr|
000000a0  61 70 70 65 72 2d 73 63  72 69 70 74 2d 31 32 31  |apper-script-121|
000000b0  31 2d 67 63 32 37 62 30  36 31*0a*30 30 33 66 37  |1-gc27b061.003f7|
000000c0  39 32 66 34 39 36 65 37  35 33 64 62 39 33 33 30  |92f496e753db9330|
000000d0  66 30 61 34 65 38 32 39  30 62 38 61 36 63 62 61  |f0a4e8290b8a6cba|
000000e0  38 61 62 36 64 61 62 20  72 65 66 73 2f 68 65 61  |8ab6dab refs/hea|
000000f0  64 73 2f 6d 61 73 74 65  72 0a 30 30 30 30        |ds/master.0000|
000000fe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Without doing any research, here’s what I think happened. The git folks defined
the fairly simple length-prefixed, newline-separated protocol. Then at some
point they wanted to add some metadata to the protocol without breaking
compatibility with older versions of git. They came up with a nifty hack that
exploits C’s null-terminated strings: add the metadata after a null byte but
before the newline. This way, reading up to a newline will get all the
metadata. The metadata-processing code knows to look past the null byte, but
the existing protocol code would see only the part up before it, presumably
letting it worked unchanged!&lt;/p&gt;

&lt;p&gt;And when I copied it using &lt;code&gt;xsel&lt;/code&gt;, the stuff past the null byte got skipped.&lt;/p&gt;

&lt;p&gt;Cute hack, and mystery solved!&lt;/p&gt;
</description>
        <pubDate>Sat, 21 Nov 2015 23:48:22 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/11/21/using-strace-to-figure-out-how-git-push-over-ssh-works/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/11/21/using-strace-to-figure-out-how-git-push-over-ssh-works/</guid>
        
        
      </item>
    
      <item>
        <title>Kubernetes from the ground up: the scheduler</title>
        <description>&lt;p&gt;&lt;em&gt;This is the third post in a series on &lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;, the open source cluster
manager. The earlier posts were about &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/&quot;&gt;the kubelet&lt;/a&gt;, and &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/&quot;&gt;the API
server&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It’s been a while since the last post, but I’m excited to finally finish this
one off. This is about the scheduler, which is the first part of what makes
Kubernetes Kubernetes. The scheduler’s job is to decide where in the cluster to
run our workloads. This lets us stop thinking about which host should run what,
and just declaratively say ‘I want this to be running’.&lt;/p&gt;

&lt;p&gt;When we left off last time, we were able to run a collection of containers on a
specific Kubernetes node by posting a JSON manifest to the API server. We also
got a look at the &lt;code&gt;kubectl&lt;/code&gt;, the command line client for Kubernetes, which
makes it much easier to interact with the cluster.&lt;/p&gt;

&lt;p&gt;Oh, except that until now we haven’t had a cluster, at least not in the sense
of multiple machines. In this post we’re going to change that. To follow along,
you’ll need a few machines—virtual, real, cloud, it doesn’t matter.
What does matter is&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;they are all on the same network&lt;/li&gt;
  &lt;li&gt;they all have Docker installed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’ve got a few machines in the examples below: the master is &lt;code&gt;master&lt;/code&gt;, while
the nodes are &lt;code&gt;node1&lt;/code&gt;, &lt;code&gt;node2&lt;/code&gt;. I’m assuming they can all be reached
via their hostnames; feel free to substitute in their IPs instead!&lt;/p&gt;

&lt;h1 id=&quot;starting-the-api-server&quot;&gt;Starting the API server&lt;/h1&gt;

&lt;p&gt;We’re going to breeze through starting the API server, since it’s
all &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/#starting-the-api-server&quot;&gt;straight out of the last post&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ mkdir etcd-data
master$ docker run --volume=$PWD/etcd-data:/default.etcd \
--detach --net=host quay.io/coreos/etcd &amp;gt; etcd-container-id
master$ wget https://storage.googleapis.com/kubernetes-release/release/v1.1.1/bin/linux/amd64/kube-apiserver
master$ chmod +x kube-apiserver
master$ ./kube-apiserver \
--etcd-servers=http://127.0.0.1:2379 \
--service-cluster-ip-range=10.0.0.0/16 \
--insecure-bind-address=0.0.0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only difference is we’ve added &lt;code&gt;--insecure-bind-address=0.0.0.0&lt;/code&gt;. This
allows the kubelets running on the nodes to connect to the API server remotely
without any authentication. Ordinarily, unauthenticated connections are only
allowed from localhost.&lt;/p&gt;

&lt;p&gt;Just to be clear, you &lt;em&gt;really&lt;/em&gt; don’t want to do this in production!&lt;/p&gt;

&lt;p&gt;While we’re here, let’s also get &lt;code&gt;kubectl&lt;/code&gt;, the command line client &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/#the-kubernetes-command-line-client-kubectl&quot;&gt;we looked
at in the last post&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ wget https://storage.googleapis.com/kubernetes-release/release/v1.1.1/bin/linux/amd64/kubectl
master$ chmod +x kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;launching-some-nodes&quot;&gt;Launching some nodes&lt;/h1&gt;

&lt;p&gt;This will be quick too, as we’ve done this a couple of times before. The only
difference here is that the API server isn’t running on localhost, so we need
to include its address. I’ve got two nodes, but I’ll just show this once below.
If you’re following along, do this on as many nodes as you want!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node1$ ./kubelet --api-servers=http://master:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now back on &lt;code&gt;master&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl get nodes
NAME      LABELS                         STATUS    AGE
node1     kubernetes.io/hostname=node1   Ready     2m
node2     kubernetes.io/hostname=node2   Ready     4s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Excellent.&lt;/p&gt;

&lt;h1 id=&quot;running-something-on-the-cluster&quot;&gt;Running something on the cluster&lt;/h1&gt;

&lt;p&gt;Kubernetes runs &lt;em&gt;pods&lt;/em&gt;, which are collections of containers that execute
together.  To start, we’ll create a pod and specify which node it should run
on.&lt;/p&gt;

&lt;p&gt;We’ll continue running our nginx example pod from the earlier posts. Get &lt;a href=&quot;https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/03-the-scheduler/nginx-with-nodename.yaml&quot;&gt;the
pod manifest&lt;/a&gt;, which specifies which containers to run. We
specify the node to run on by setting the &lt;code&gt;nodeName&lt;/code&gt; field. Edit the file and
set it to run on one of your nodes.  I picked &lt;code&gt;node2&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/03-the-scheduler/nginx-with-nodename.yaml
master$ $EDITOR nginx-with-nodename.yaml  # edit the nodeName field to match a node
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now create the pod:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl create --filename nginx-with-nodename.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can check with &lt;code&gt;kubectl get pods&lt;/code&gt; we see that it got picked up. If you’re
quicker than me, you might catch it in the &lt;code&gt;Pending&lt;/code&gt; state, before the kubelet
starts it, but it should end up &lt;code&gt;Running&lt;/code&gt; fairly quickly.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl get pods
NAME                  READY     STATUS    RESTARTS   AGE
nginx-with-nodename   2/2       Running   0          7s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just to be sure it’s actually on &lt;code&gt;node2&lt;/code&gt; as we said, we can &lt;code&gt;kubectl describe&lt;/code&gt;
the pod:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl describe pods/nginx-with-nodename | grep ^Node
Node:                           node2/10.240.0.4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can break down what happened here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;initially, the kubelets on each node are watching the API server for pods
they are meant to be running&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt; created a pod on the API server that’s meant to run on &lt;code&gt;node2&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;the kubelet on &lt;code&gt;node2&lt;/code&gt; noticed the new pod, and so started running it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can also try &lt;a href=&quot;https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/03-the-scheduler/nginx-without-nodename.yaml&quot;&gt;a pod manifest&lt;/a&gt; that doesn’t specify a
node to run on. In our current setup, this pod will forever sit in the
&lt;code&gt;Pending&lt;/code&gt; state. Let’s try anyway:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/03-the-scheduler/nginx-without-nodename.yaml
master$ ./kubectl create --filename nginx-without-nodename.yaml
master$ ./kubectl get pods
NAME                     READY     STATUS    RESTARTS   AGE
nginx-with-nodename      2/2       Running   0          3m
nginx-without-nodename   0/2       Pending   0          20s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even if you take a break and read the internet for 15 minutes, it’ll still be
there, &lt;code&gt;Pending&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl get pods
NAME                     READY     STATUS    RESTARTS   AGE
nginx-with-nodename      2/2       Running   0          18m
nginx-without-nodename   0/2       Pending   0          15m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Breaking it down in the same way:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;initially, the kubelets on each node are watching the API server for pods
they are meant to be running&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt; created a pod on the API server without specifying which node to
run on&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;… yeah, nothing’s going to happen.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-scheduler&quot;&gt;The scheduler&lt;/h1&gt;

&lt;p&gt;This is where the sheduler comes in: its job is to take pods that aren’t bound
to a node, and assign them one. Once the pod has a node assigned, the normal
behavior of the kubelet kicks in, and the pod gets started.&lt;/p&gt;

&lt;p&gt;Let’s get the scheduler binary and start it running on &lt;code&gt;master&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ wget https://storage.googleapis.com/kubernetes-release/release/v1.1.1/bin/linux/amd64/kube-scheduler
master$ chmod +x kubectl
master$ ./kube-scheduler --master=http://localhost:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not long after starting the scheduler, the &lt;code&gt;nginx-without-nodename&lt;/code&gt; pod should
get assigned a node and start running.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl get pods
NAME                     READY     STATUS    RESTARTS   AGE
nginx-with-nodename      2/2       Running   0          1h
nginx-without-nodename   2/2       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we &lt;code&gt;describe&lt;/code&gt; it, we can see which node it got scheduled on:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl describe pods/nginx-without-nodename | grep ^Node
Node:                           node1/10.240.0.3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It ended up on &lt;code&gt;node1&lt;/code&gt;! The scheduler tries to spread out pods evenly across
the nodes we have available, so that makes sense. If you’re interested in more
about how the scheduler places pods, there’s a really good &lt;a href=&quot;http://stackoverflow.com/a/28874577&quot;&gt;Stack
Overflow&lt;/a&gt; answer with some details.&lt;/p&gt;

&lt;p&gt;We can also get a list of ‘events’ related to the pod. These are state changes
through the pods lifetime:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl describe pods/nginx-without-nodename | grep -A5 ^Events
Events:
  FirstSeen     LastSeen        Count   From            SubobjectPath                           Reason                  Message
  ─────────     ────────        ─────   ────            ─────────────                           ──────                  ───────
  25m           25m             1       {scheduler }                                            Scheduled               Successfully assigned nginx-without-nodename to node1
  23m           23m             1       {kubelet node1} implicitly required container POD       Pulling                 Pulling image &quot;gcr.io/google_containers/pause:0.8.0&quot;
  23m           23m             1       {kubelet node1} implicitly required container POD       Pulled                  Successfully pulled image &quot;gcr.io/google_containers/pause:0.8.0&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first one shows it getting scheduled, then others are related to the pod
starting up on the node.&lt;/p&gt;

&lt;p&gt;At this point, if you create another pod without specifying a node for it to
run on, the scheduler will place it right away. Try it out!&lt;/p&gt;

&lt;h1 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h1&gt;

&lt;p&gt;So now we are able to declaratively specify workloads, and get them scheduled
across our cluster, which is great! But if we actually try connecting to the
nginx servers we have running, we’ll see we have a little problem:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;master$ ./kubectl describe pods/nginx-with-nodename | grep ^IP
IP:                             172.17.0.2
master$ curl http://172.17.0.2
curl: (7) Failed to connect to 172.17.0.2 port 80: No route to host
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This pod is running on &lt;code&gt;node2&lt;/code&gt;. If we go over to that machine,
we get through:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node2$ curl --stderr /dev/null http://172.17.0.2 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But our other node can’t reach it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node1$ curl http://172.17.0.2
curl: (7) Failed to connect to 172.17.0.2 port 80: No route to host
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the next post, we’ll take a little detour into Kubernetes networking, and
make it possible for containers to talk to each other over the network.&lt;/p&gt;
</description>
        <pubDate>Tue, 17 Nov 2015 17:41:57 -0500</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/11/17/kubernetes-from-the-ground-up-the-scheduler/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/11/17/kubernetes-from-the-ground-up-the-scheduler/</guid>
        
        
      </item>
    
      <item>
        <title>Eliminating branches in Rust for fun... but not much profit</title>
        <description>&lt;p&gt;Last week, I nerd-sniped myself after reading a &lt;a href=&quot;http://m4rw3r.github.io/parser-combinator-experiments-part-3/&quot;&gt;blog post&lt;/a&gt; about
performance of parser combinators in Rust, and the associated &lt;a href=&quot;https://www.reddit.com/r/rust/comments/3k0d0d/parser_combinator_experiments_part_3_performance/&quot;&gt;Reddit
discussion&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The benchmark in the post was parsing a bunch of HTTP requests. The focus was
on improving performance of a function determining if a character formed part
of a token. In the post, it was changed from&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fn is_token(c: u8) -&amp;gt; bool {
    c &amp;lt; 128 &amp;amp;&amp;amp; c &amp;gt; 31 &amp;amp;&amp;amp; b&quot;()&amp;lt;&amp;gt;@,;:\\\&quot;/[]?={} \t&quot;.iter()
                           .position(|&amp;amp;i| i == c).is_none()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which iterates over a list of characters, to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fn is_token(c: u8) -&amp;gt; bool {
    // roughly follows the order of ascii chars: &quot;\&quot;(),/:;&amp;lt;=&amp;gt;?@[\\]{} \t&quot;
    c &amp;lt; 128 &amp;amp;&amp;amp; c &amp;gt; 32 &amp;amp;&amp;amp; c != b&#39;\t&#39; &amp;amp;&amp;amp; c != b&#39;&quot;&#39; &amp;amp;&amp;amp; c != b&#39;(&#39; &amp;amp;&amp;amp; c != b&#39;)&#39; &amp;amp;&amp;amp;
        c != b&#39;,&#39; &amp;amp;&amp;amp; c != b&#39;/&#39; &amp;amp;&amp;amp; !(c &amp;gt; 57 &amp;amp;&amp;amp; c &amp;lt; 65) &amp;amp;&amp;amp; !(c &amp;gt; 90 &amp;amp;&amp;amp; c &amp;lt; 94) &amp;amp;&amp;amp;
        c != b&#39;{&#39; &amp;amp;&amp;amp; c != b&#39;}&#39;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which unrolls the loop into a big boolean conjunction.&lt;/p&gt;

&lt;p&gt;On my machine, the benchmark with the original version takes about 106
microseconds to parse a text file containing about 50 HTTP requests. The newer
version takes 73 microseconds, which is about 30% faster.&lt;/p&gt;

&lt;p&gt;After reading this, I started thinking something like “I know about CPUs, and
branches are bad because of mispredictions or something”, and “LOOK &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; AT
&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; ALL &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; THOSE &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; BRANCHES!”, and imagining fame and fortune for making
it even faster.&lt;/p&gt;

&lt;p&gt;This led me down a path of trying to replace that function with a
straight-through series of bitwise operations. First off, let’s unpack what’s
actually being checked in this function:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;c &amp;lt; 128&lt;/code&gt;: that &lt;code&gt;c&lt;/code&gt; represents asn ASCII character&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;c &amp;gt; 32&lt;/code&gt;: that &lt;code&gt;c&lt;/code&gt; is not a control character or space&lt;/li&gt;
  &lt;li&gt;all the &lt;code&gt;!=&lt;/code&gt; comparisons: that &lt;code&gt;c&lt;/code&gt; isn’t any of those characters&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;!(c &amp;gt; 57 &amp;amp;&amp;amp; c &amp;lt; 65)&lt;/code&gt;: that &lt;code&gt;c&lt;/code&gt; is none of &lt;code&gt;:;&amp;lt;=&amp;gt;?@&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;!(c &amp;gt; 90 &amp;amp;&amp;amp; c &amp;lt; 94)&lt;/code&gt;: that &lt;code&gt;c&lt;/code&gt; is none of &lt;code&gt;[\]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;eliminate-almost-all-the-branches&quot;&gt;Eliminate (almost) ALL THE BRANCHES&lt;/h1&gt;

&lt;p&gt;My basic idea was to replace all the equality checks with XOR, and all the
boolean ands with bitwise ands. Boolean ands (&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;) and ors (&lt;code&gt;||&lt;/code&gt;) have short
circuiting semantics: their right hand sides are only evaluated if necessary.
This means that &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; has to be implemented as a conditional jump to avoid
evaluating the right hand side if the left hand side is false.&lt;/p&gt;

&lt;p&gt;To check I was making any sense, I used the fantastic Godbolt interactive
compiler, which &lt;a href=&quot;http://rust.godbolt.org/&quot;&gt;has Rust support&lt;/a&gt;. This confirmed that at least
some of the boolean ands were compiling to conditional jumps, which was enough
for me to go down the bitwise operation path.&lt;/p&gt;

&lt;p&gt;After spending a bunch of time on translating it to be purely bitwise
operations, I ended up with this performance result:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test bench_http ... bench:     230,030 ns/iter (+/- 6,303)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;About three times slower. This was… disappointing. Especially because along
the way, a broken benchmark setup had me convinced I sped things up by 60%!&lt;/p&gt;

&lt;h1 id=&quot;why-so-slow&quot;&gt;Why so slow?&lt;/h1&gt;

&lt;p&gt;I talked about my results with Dan Luu, since he’s written about this kind of
thing before. He mentioned that on Haswell, the missed branch prediction
penalty is about 14 cycles. Optimally organised bitwise operations can be
about 4 per cycle.&lt;/p&gt;

&lt;p&gt;The original version had about 30 instructions, of which about 6 were branches.
Assuming one instruction per cycle, a really bad branch predictor miss rate
like 50% would be somewhere around 75 cycles.  The bitwise version had about
130 instructions, of which one was a branch. Assume the branch predictor is
always right, that still puts me at 40+ cycles if 3 are in parallel.&lt;/p&gt;

&lt;p&gt;In summary, unless the branch predictor was abysmally bad at this code, or I
was amazingly excellent at organizing the bitwise operations, there was no
strong reason to expect my my bitwise version to be faster.&lt;/p&gt;

&lt;p&gt;This got me to run &lt;code&gt;perf stat&lt;/code&gt; on the benchmark to get a look at the branch
prediction hit rate. This turned out to be above 99.5%, which is far from
‘abysmal’.&lt;/p&gt;

&lt;h1 id=&quot;another-approach-a-lookup-table&quot;&gt;Another approach: a lookup table&lt;/h1&gt;

&lt;p&gt;The discussion also suggested implementing this as a lookup table. This would
reduce &lt;code&gt;is_token&lt;/code&gt; to a single load which can be inlined wherever it’s used.
Rust represents boolean values as bytes, so the table will be 256 bytes which
should mean we’ll rarely have to go too far down the cache hierarchy.&lt;/p&gt;

&lt;p&gt;Indeed, implementing that gave a modest 6-7%  performance improvement over the
version that sent me off on this investigation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test bench_http ... bench:      67,890 ns/iter (+/- 1,913)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So at least there was a somewhat satisfactory result at the end!&lt;/p&gt;

&lt;h1 id=&quot;the-moral-of-the-story-validate-assumptions-and-know-more-numbers&quot;&gt;The moral of the story: validate assumptions, and know more numbers!&lt;/h1&gt;

&lt;p&gt;There were a couple of big takeaways for me. The first is I could have saved
myself a whole bunch of time if I’d investigated the branch prediction
performance before embarking on this adventure. Instead of assuming the
branching was slowing things down, I would know that it probably wasn’t.&lt;/p&gt;

&lt;p&gt;The other was knowing some performance numbers offhand could have helped a lot
here. I have a rough idea of L1 / L2 latency, and main memory latency. But I
had no idea how many bitwise operations to expect per cycle, or how bad a
branch misprediction was. I’ve now added these to my collection, but knowing a
few more rough figures like that would certainly be good!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Thanks to Dan Luu, Anton Dubrau, and David Turner for useful and interesting
discussions, and to Julia Evans for reading drafts of this post.&lt;/em&gt;&lt;/p&gt;

&lt;!--

# How I implemented a bitwise version
Here&#39;s how I built up my bitwise version. For my own sanity, and ease of
translation, I decided to use `0x0` as false and `0x1` as true. Implement first
and improve afterwards if it seems hopeful. I started off using the fact that
`x ^ y` is all zeros if and only if `x` and `y` are equal. Or, put another way,
if `x != y` at least one bit in `x ^ y` is set. This will be handy since most
of our comparisons are checking inequality with a fixed byte. This lets us
write

~~~
fn eq(x: u8, y: u8) -&gt; u8 {
    not(is_non_zero(x ^ y))
~~~

We need `is_non_zero` to return `0x1` or `0x0`; we&#39;ll get to that in a second.
Once it does, the `not` operation is easy: just XOR with `0x1`:

~~~
fn not(x: u8) -&gt; u8 {
    x ^ 1
}
~~~

As for this `is_non_zero` operation, that&#39;s a bit trickier. Fortunately, [the
internet][stackoverflow]! Here&#39;s the implementation:

~~~
fn is_non_zero(x: u8) -&gt; u8 {
    ((x | ((!x).wrapping_add(1))) &gt;&gt; 7)
}
~~~

What we want to do is return `0x1` if any bit of `x` is set, and otherwise
return `0x0`. We&#39;ll work out how this works from the outside in. If we can get the most signicant bit set in The way this works is to force the most significant bit to be set
if any bit is set. Then the `&gt;&gt; 7` will bring the most significant bit down to
be the least significant bit, and we&#39;ll have 

Finally, we&#39;ve got comparisons with `128` and `32`. Both of these are powers of
two, which makes it a bit easier to check! If the most significant bit is set,
then the number is greater than or equal to `128`, so we bitwise and with `128`
and check if that&#39;s non-zero:


~~~
pub fn ge_128(x: u8) -&gt; u8 {
    is_non_zero(128 &amp; x)
}
~~~

For checking a number is less than `32`, we need to check that none of the upper 3 bits are set. For this, we can bitwise and with the bitwise compelement of 31, which has all the lower 5 bits set.

~~~
pub fn lt_32(x: u8) -&gt; u8 {
    not(is_non_zero(!0x1f &amp; x))
}
~~~

Finally, we need a way to go from `0x1` and `0x0` to `true` and `false`. Since we only have

This let me put the whole thing together:


[stackoverflow]: http://stackoverflow.com/questions/3912112/check-if-a-number-is-non-zero-using-bitwise-operators-in-c
--&gt;
</description>
        <pubDate>Tue, 15 Sep 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/09/15/eliminating-branches-in-rust-for-fun-but-not-much-profit/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/09/15/eliminating-branches-in-rust-for-fun-but-not-much-profit/</guid>
        
        
      </item>
    
      <item>
        <title>Kubernetes from the ground up: the API server</title>
        <description>&lt;p&gt;&lt;em&gt;This is the second post in a series on &lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;, the open source cluster
manager. The first post was &lt;a href=&quot;http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/&quot;&gt;about the kubelet&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/&quot;&gt;Last time&lt;/a&gt; we took a look at the kubelet, Kubernetes’
container-focused process watcher. The kubelet runs pods, which are collections
of containers that share an IP and some volumes. In the post, we gave it pods
to run by putting pod manifest files in directory it watched. This was a great
way to understand the core purpose of the kubelet.  In a Kubernetes cluster,
however, a kubelet will get most its pods to run from the Kubernetes API
server.&lt;/p&gt;

&lt;p&gt;Kubernetes stores all its cluster state in &lt;a href=&quot;https://github.com/coreos/etcd&quot;&gt;etcd&lt;/a&gt;, a distributed data store with
a strong consistency model. This state includes what nodes exist in the cluster,
what pods should be running, which nodes they are running on, and a whole lot
more. The API server is the only Kubernetes component that connects to etcd; all
the other components must go through the API server to work with cluster state.
In this post we’ll look at the API server, and its interaction with the kubelet.&lt;/p&gt;

&lt;h1 id=&quot;starting-the-api-server&quot;&gt;Starting the API server&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;You may need to use &lt;code&gt;sudo&lt;/code&gt; on some commands, depending on your setup.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;First off, we’re going to need etcd running. Luckily this is as easy as creating
a directory for it to store its state and starting it with Docker. We’ll also
save the Docker container ID so we can stop the container later.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir etcd-data
$ docker run --volume=$PWD/etcd-data:/default.etcd \
--detach --net=host quay.io/coreos/etcd &amp;gt; etcd-container-id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use host networking so that the API server can talk to it at &lt;code&gt;127.0.0.1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next we’ll want the API server binary:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://storage.googleapis.com/kubernetes-release/release/v1.0.3/bin/linux/amd64/kube-apiserver
$ chmod +x kube-apiserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can start it up. It needs to know where the etcd server is, as well as
the service cluster IP range. We’ll save talking about what the IP range is for
a later post that will go into Kubernetes’ services and networking. For now
we’ll just provide &lt;code&gt;10.0.0.0/16&lt;/code&gt; so that the API server starts up without
shouting at us!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kube-apiserver \
--etcd-servers=http://127.0.0.1:2379 \
--service-cluster-ip-range=10.0.0.0/16 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now &lt;code&gt;curl&lt;/code&gt; around and check a few things out. First off, we can get a
list of nodes in our cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:8080/api/v1/nodes
{
  &quot;kind&quot;: &quot;NodeList&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    &quot;selfLink&quot;: &quot;/api/v1/nodes&quot;,
    &quot;resourceVersion&quot;: &quot;150&quot;
  },
  &quot;items&quot;: []
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not surprisingly, there aren’t any yet.&lt;/p&gt;

&lt;p&gt;As a quick note on other fields in the response: the &lt;code&gt;kind&lt;/code&gt; and &lt;code&gt;apiVersion&lt;/code&gt;
are giving information about the API version and type of response we got. The
&lt;code&gt;selfLink&lt;/code&gt; field is a canonical link for the resource in the response. The
&lt;code&gt;resourceVersion&lt;/code&gt; is used for concurrency control. Clients send it back when
they are changing a resource, and the server can determine if there was a
conflicting write to the same resource in the meantime.&lt;/p&gt;

&lt;p&gt;All that is to say: right now we only care about the &lt;code&gt;items&lt;/code&gt; field. We can use
the incredibly handy &lt;a href=&quot;https://stedolan.github.io/jq/&quot;&gt;&lt;code&gt;jq&lt;/code&gt;&lt;/a&gt; utility to just get at the items. We’ll use &lt;code&gt;jq&lt;/code&gt;
to cut out noisy bits of responses throughout this post. For example, we can
look at what pods our cluster is running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:8080/api/v1/pods | jq &#39;.items&#39;
[]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No surprises there, either!&lt;/p&gt;

&lt;h1 id=&quot;adding-a-node&quot;&gt;Adding a node&lt;/h1&gt;

&lt;p&gt;In the last post, we had the kubelet watching for pod manifest files in a
directory we gave it via the &lt;code&gt;--config&lt;/code&gt; flag. This time we’ll have it get pod
manifests from the API server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubelet --api-servers=127.0.0.1:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When a kubelet starts up, it registers itself as a node with the API server and
starts watching for pods to run. This is really great, because it means that
when we get to running a multinode cluster, we can add nodes without having to
reconfigure the API server.&lt;/p&gt;

&lt;p&gt;We can check that the API server knows about our node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:8080/api/v1/nodes/ \
| jq &#39;.items&#39; | head
[
  {
    &quot;metadata&quot;: {
      &quot;name&quot;: &quot;awesome-node&quot;,
      &quot;selfLink&quot;: &quot;/api/v1/nodes/awesome-node&quot;,
      &quot;uid&quot;: &quot;6811f7b0-5181-11e5-b364-68f7288bdc45&quot;,
      &quot;resourceVersion&quot;: &quot;246&quot;,
      &quot;creationTimestamp&quot;: &quot;2015-09-02T14:46:34Z&quot;,
      &quot;labels&quot;: {
        &quot;kubernetes.io/hostname&quot;: &quot;awesome-node&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have a one-node cluster!&lt;/p&gt;

&lt;h1 id=&quot;running-a-pod-via-the-api-server&quot;&gt;Running a pod via the API server&lt;/h1&gt;

&lt;p&gt;Let’s run our nginx example from the last post:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/01-the-kubelet/nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In a complete Kubernetes cluster, the scheduler will decide which node to run a
pod on. For now, we’ve only got the API server and a kubelet, so we’ll have to
specify it ourselves. To do this, we need to add a &lt;code&gt;nodeName&lt;/code&gt; to the spec with
the node’s &lt;code&gt;name&lt;/code&gt; from above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sed --in-place &#39;/spec:/a\ \ nodeName: awesome-node&#39; nginx.yaml
$ head nginx.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: awesome-node
  containers:
  - name: nginx
    image: nginx
    ports:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the &lt;code&gt;nodeName&lt;/code&gt; configured, we’re almost ready to send the pod manifest to
the API server. Unfortunately, it only speaks JSON so we have to convert our YAML to
JSON:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ruby -ryaml -rjson \
-e &#39;puts JSON.pretty_generate(YAML.load(ARGF))&#39; &amp;lt; nginx.yaml &amp;gt; nginx.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, just download the &lt;a href=&quot;https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.json&quot;&gt;JSON file&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.yaml&quot;&gt;YAML
file&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.json
$ wget https://raw.githubusercontent.com/kamalmarhubi/kubernetes-from-the-ground-up/master/02-the-api-server/nginx.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then edit the files so that the &lt;code&gt;nodeName&lt;/code&gt; matches your hostname.&lt;/p&gt;

&lt;p&gt;Now we can post the JSON pod manifest to the API server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl \
--stderr /dev/null \
--request POST http://localhost:8080/api/v1/namespaces/default/pods \
--data @nginx.json | jq &#39;del(.spec.containers, .spec.volumes)&#39;
{
  &quot;kind&quot;: &quot;Pod&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    &quot;name&quot;: &quot;nginx&quot;,
    &quot;namespace&quot;: &quot;default&quot;,
    &quot;selfLink&quot;: &quot;/api/v1/namespaces/default/pods/nginx&quot;,
    &quot;uid&quot;: &quot;28aa5a55-5194-11e5-b364-68f7288bdc45&quot;,
    &quot;resourceVersion&quot;: &quot;1365&quot;,
    &quot;creationTimestamp&quot;: &quot;2015-09-02T17:00:48Z&quot;
  },
  &quot;spec&quot;: {
    &quot;restartPolicy&quot;: &quot;Always&quot;,
    &quot;dnsPolicy&quot;: &quot;ClusterFirst&quot;,
    &quot;nodeName&quot;: &quot;awesome-node&quot;
  },
  &quot;status&quot;: {
    &quot;phase&quot;: &quot;Pending&quot;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a short wait, the kubelet should have started the pod. We can check this
by making a GET request:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:8080/api/v1/namespaces/default/pods \
| jq &#39;.items[] | { name: .metadata.name, status: .status} | del(.status.containerStatuses)&#39;
{
  &quot;name&quot;: &quot;nginx&quot;,
  &quot;status&quot;: {
    &quot;phase&quot;: &quot;Running&quot;,
    &quot;conditions&quot;: [
      {
        &quot;type&quot;: &quot;Ready&quot;,
        &quot;status&quot;: &quot;True&quot;
      }
    ],
    &quot;hostIP&quot;: &quot;127.0.1.1&quot;,
    &quot;podIP&quot;: &quot;172.17.0.37&quot;,
    &quot;startTime&quot;: &quot;2015-09-02T18:00:00Z&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The pod is up, and it’s been assigned the IP &lt;code&gt;172.17.0.37&lt;/code&gt; by Docker. Docker
networking is really quite interesting, and well worth reading about. A good
place to start is &lt;a href=&quot;https://docs.docker.com/articles/networking/&quot;&gt;the network configuration article&lt;/a&gt; in the Docker
documentation.&lt;/p&gt;

&lt;p&gt;Let’s check that nginx is reachable at that IP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://172.17.0.37 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Excellent!&lt;/p&gt;

&lt;h1 id=&quot;the-kubernetes-command-line-client-kubectl&quot;&gt;The Kubernetes command line client: kubectl&lt;/h1&gt;

&lt;p&gt;While it’s great to know that the API server speaks a fairly intelligible REST
dialect, talking to it directly with &lt;code&gt;curl&lt;/code&gt; and using &lt;code&gt;jq&lt;/code&gt; to filter the
responses isn’t the best user experience. This is a great point to pause and
introduce the command line client&lt;a href=&quot;http://kubernetes.io/v1.0/docs/user-guide/kubectl/kubectl.html&quot;&gt; &lt;code&gt;kubectl&lt;/code&gt;&lt;/a&gt;, which we’ll use
throughout the rest of this series. It will make things &lt;strong&gt;much&lt;/strong&gt; nicer!&lt;/p&gt;

&lt;p&gt;First off, let’s download the client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://storage.googleapis.com/kubernetes-release/release/v1.0.3/bin/linux/amd64/kubectl
$ chmod +x kubectl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can get the list of nodes and see what pods are running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl get nodes
NAME      LABELS                      STATUS
awesome-node        kubernetes.io/hostname=awesome-node   Ready
$ ./kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
nginx     2/2       Running   0          28m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much easier and prettier! Creating pods is also easier with &lt;code&gt;kubectl&lt;/code&gt;. Let’s
create a copy of the nginx pod manifest with a different name.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sed &#39;s/^  name:.*/  name: nginx-the-second/&#39; nginx.yaml &amp;gt; nginx2.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can use &lt;code&gt;kubectl create&lt;/code&gt; to start another copy.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl create --filename nginx2.yaml
pods/nginx-the-second
$ ./kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
nginx              2/2       Running   0          1h
nginx-the-second   0/2       Running   0          6s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we’ve got our second nginx pod running, but it reports &lt;code&gt;0/2&lt;/code&gt; containers
running. Let’s give it a bit and try again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl get pods
NAME               READY     STATUS    RESTARTS   AGE
nginx              2/2       Running   0          1h
nginx-the-second   2/2       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also use &lt;code&gt;kubectl describe&lt;/code&gt; to get at more detailed information on the
pod:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl describe pods/nginx-the-second | head
Name:                           nginx-the-second
Namespace:                      default
Image(s):                       nginx,busybox
Node:                           awesome-node/127.0.1.1
Labels:                         &amp;lt;none&amp;gt;
Status:                         Running
Reason:
Message:
IP:                             172.17.0.38
Replication Controllers:        &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And just to be sure, we can check that this pod’s nginx is also up and serving
requests at the pod’s IP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://172.17.0.38 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! So now we’ve seen what it’s like to start a server in Kubernetes using
the command line client. We’ve still got a little way to go before this is a
full-blown Kubernetes cluster, but we are inching closer. Next time we’ll bring
in the scheduler and add a couple more nodes into the mix.&lt;/p&gt;

&lt;p&gt;For now, let’s just tear everything down:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./kubectl delete pods/nginx pods/nginx-the-second
pods/nginx
pods/nginx-the-second
$ ./kubectl get pods
NAME      READY     STATUS    RESTARTS   AGE
$ docker stop $(cat etcd-container-id)
$ sleep 20  # wait for the Kubelet to stop all the containers
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Thanks to Johannes Alkjær, Julia Evans, Ray Bejjani, and Tavish Armstrong for
reviewing drafts of this post.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Sep 2015 12:02:47 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/09/06/kubernetes-from-the-ground-up-the-api-server/</guid>
        
        
      </item>
    
      <item>
        <title>What even is a kubelet?</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; is Google’s open source, container-focused cluster management
thing.  I see it as their attempt to tell everyone how they think containers
and clusters fit together. The Kubernetes documentation is quite good, but it’s
divided up in a way that makes it great as a reference. I want to understand
both the concepts Kubernetes introduces, and the components that make up a
Kubernetes cluster, and I want to learn by doing. I’m planning to build up a
cluster from scratch, documenting the moving parts and concepts as I go.&lt;/p&gt;

&lt;p&gt;I’ll start of with a look at the &lt;em&gt;&lt;a href=&quot;http://kubernetes.io/v1.0/docs/admin/kubelet.html&quot;&gt;kubelet&lt;/a&gt;&lt;/em&gt;, which is the lowest level component
in Kubernetes. It’s responsible for what’s running on an individual machine.
You can think of it as a process watcher like &lt;a href=&quot;http://supervisord.org/&quot;&gt;supervisord&lt;/a&gt;, but focused on
running containers. It has one job: given a set of containers to run, make sure
they are all running.&lt;/p&gt;

&lt;h1 id=&quot;kubelets-run-pods&quot;&gt;Kubelets run pods&lt;/h1&gt;

&lt;p&gt;The unit of execution that Kubernetes works with is the &lt;em&gt;&lt;a href=&quot;http://kubernetes.io/v1.0/docs/user-guide/pods.html&quot;&gt;pod&lt;/a&gt;&lt;/em&gt;. A pod is a
collection of containers that share some resources: they have a single IP, and
can share volumes. For example, a web server pod could have a container for the
server itself, and a container that tails the logs and ships them off to your
logging or metrics infrastructure.&lt;/p&gt;

&lt;p&gt;Pods are defined by a JSON or YAML file called a pod manifest. A simple one
with one container looks like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-coderay&quot;&gt;&lt;div class=&quot;CodeRay&quot;&gt;
  &lt;div class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n1&quot; name=&quot;n1&quot;&gt;1&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;apiVersion&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;v1&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n2&quot; name=&quot;n2&quot;&gt;2&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;kind&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;Pod&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n3&quot; name=&quot;n3&quot;&gt;3&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;metadata&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n4&quot; name=&quot;n4&quot;&gt;4&lt;/a&gt;&lt;/span&gt;  &lt;span style=&quot;color:#606&quot;&gt;name&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n5&quot; name=&quot;n5&quot;&gt;5&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;spec&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n6&quot; name=&quot;n6&quot;&gt;6&lt;/a&gt;&lt;/span&gt;  &lt;span style=&quot;color:#606&quot;&gt;containers&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n7&quot; name=&quot;n7&quot;&gt;7&lt;/a&gt;&lt;/span&gt;  - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;name: nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n8&quot; name=&quot;n8&quot;&gt;8&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;image&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n9&quot; name=&quot;n9&quot;&gt;9&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;ports&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt;&lt;strong&gt;&lt;a href=&quot;#n10&quot; name=&quot;n10&quot;&gt;10&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;    - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;containerPort: 80&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The container’s &lt;code&gt;image&lt;/code&gt; is a Docker image name. The &lt;code&gt;containerPort&lt;/code&gt; exposes
that port from the nginx container so we can connect to the nginx server at the
pod’s IP. By default, the &lt;a href=&quot;http://docs.docker.com/reference/builder/#entrypoint&quot;&gt;entrypoint&lt;/a&gt; defined in the image is what will run; in
the nginx image, that’s the nginx server.&lt;/p&gt;

&lt;p&gt;Let’s add a log truncator container to this pod. This will take care of the
nginx access log, truncating it every 10 seconds—who needs those anyway? To do
this, we’ll need nginx to write its logs to a volume that can be shared to the
log truncator. We’ll set this volume up as an &lt;code&gt;emptyDir&lt;/code&gt; volume: it will start
off as an empty directory when the pod starts, and be cleaned up when the pod
exits, but will persist across restarts of the component containers.&lt;/p&gt;

&lt;p&gt;Here’s the updated pod manifest:&lt;/p&gt;

&lt;div class=&quot;highlighter-coderay&quot;&gt;&lt;div class=&quot;CodeRay&quot;&gt;
  &lt;div class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n1&quot; name=&quot;n1&quot;&gt;1&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;apiVersion&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;v1&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n2&quot; name=&quot;n2&quot;&gt;2&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;kind&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;Pod&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n3&quot; name=&quot;n3&quot;&gt;3&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;metadata&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n4&quot; name=&quot;n4&quot;&gt;4&lt;/a&gt;&lt;/span&gt;  &lt;span style=&quot;color:#606&quot;&gt;name&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n5&quot; name=&quot;n5&quot;&gt;5&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#606&quot;&gt;spec&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n6&quot; name=&quot;n6&quot;&gt;6&lt;/a&gt;&lt;/span&gt;  &lt;span style=&quot;color:#606&quot;&gt;containers&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n7&quot; name=&quot;n7&quot;&gt;7&lt;/a&gt;&lt;/span&gt;  - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;name: nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n8&quot; name=&quot;n8&quot;&gt;8&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;image&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt; &lt;a href=&quot;#n9&quot; name=&quot;n9&quot;&gt;9&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;ports&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt;&lt;strong&gt;&lt;a href=&quot;#n10&quot; name=&quot;n10&quot;&gt;10&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;    - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;containerPort: 80&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n11&quot; name=&quot;n11&quot;&gt;11&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;volumeMounts&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n12&quot; name=&quot;n12&quot;&gt;12&lt;/a&gt;&lt;/span&gt;    - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;mountPath: /var/log/nginx&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n13&quot; name=&quot;n13&quot;&gt;13&lt;/a&gt;&lt;/span&gt;      &lt;span style=&quot;color:#606&quot;&gt;name&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;nginx-logs&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n14&quot; name=&quot;n14&quot;&gt;14&lt;/a&gt;&lt;/span&gt;  - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;name: log-truncator&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n15&quot; name=&quot;n15&quot;&gt;15&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;image&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;busybox&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n16&quot; name=&quot;n16&quot;&gt;16&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;command&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n17&quot; name=&quot;n17&quot;&gt;17&lt;/a&gt;&lt;/span&gt;    - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;/bin/sh&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n18&quot; name=&quot;n18&quot;&gt;18&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;args&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;[-c, &#39;while true; do cat /dev/null &amp;gt; /logdir/access.log; sleep 10; done&#39;]&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n19&quot; name=&quot;n19&quot;&gt;19&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;volumeMounts&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt;&lt;strong&gt;&lt;a href=&quot;#n20&quot; name=&quot;n20&quot;&gt;20&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;    - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;mountPath: /logdir&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n21&quot; name=&quot;n21&quot;&gt;21&lt;/a&gt;&lt;/span&gt;      &lt;span style=&quot;color:#606&quot;&gt;name&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;nginx-logs&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n22&quot; name=&quot;n22&quot;&gt;22&lt;/a&gt;&lt;/span&gt;  &lt;span style=&quot;color:#606&quot;&gt;volumes&lt;/span&gt;:
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n23&quot; name=&quot;n23&quot;&gt;23&lt;/a&gt;&lt;/span&gt;  - &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;name: nginx-logs&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;line-numbers&quot;&gt;&lt;a href=&quot;#n24&quot; name=&quot;n24&quot;&gt;24&lt;/a&gt;&lt;/span&gt;    &lt;span style=&quot;color:#606&quot;&gt;emptyDir&lt;/span&gt;: &lt;span style=&quot;background-color:hsla(0,100%,50%,0.05)&quot;&gt;&lt;span style=&quot;color:#D20&quot;&gt;{}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;We’ve added an &lt;code&gt;emptyDir&lt;/code&gt; volume named &lt;code&gt;nginx-logs&lt;/code&gt;. nginx writes its logs at
/var/log/nginx, so we mount that volume at that location in the &lt;code&gt;nginx&lt;/code&gt;
container. For the &lt;code&gt;log-truncator&lt;/code&gt; container, we’re using the &lt;a href=&quot;https://hub.docker.com/_/busybox/&quot;&gt;busybox&lt;/a&gt; image.
It’s a tiny Linux command line environment, which provides everything we need
for a robust log truncator. Inside that container, we’ve mounted the
&lt;code&gt;nginx-logs&lt;/code&gt; volume at &lt;code&gt;/logdir&lt;/code&gt;. We set its &lt;code&gt;command&lt;/code&gt; and &lt;code&gt;args&lt;/code&gt; up to run a
shell loop that truncates the log file every 10 seconds.&lt;/p&gt;

&lt;p&gt;Now we’ve got this paragon of production infrastructure configured, it’s time
to run it!&lt;/p&gt;

&lt;h1 id=&quot;running-a-pod&quot;&gt;Running a pod&lt;/h1&gt;

&lt;p&gt;There are a few ways the kubelet finds pods to run:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a directory it polls for new pod manifests to run&lt;/li&gt;
  &lt;li&gt;a URL it polls and downloads pod manifests from&lt;/li&gt;
  &lt;li&gt;from the Kubernetes API server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first of these is definitely the simplest: to run a pod, we just put a
manifest file in the watched directory. Every 20 seconds, the kubelet checks
for changes in the directory, and adjusts what it’s running based on what it
finds.  This means both launching pods that are added, as well as killing ones
that are removed.&lt;/p&gt;

&lt;p&gt;The kubelet is such a low level component with such limited responsibilities
that we can actually use it independently of Kubernetes—all we have to do is
not tell it about a Kubernetes API server. The kubelet supports &lt;a href=&quot;https://github.com/docker/docker&quot;&gt;Docker&lt;/a&gt; and
&lt;a href=&quot;https://github.com/coreos/rkt&quot;&gt;rkt&lt;/a&gt; as continer runtimes. The default is Docker, and that’s what we’ll use in
the examples here. You’ll need a machine with Docker installed and running to
try this out.&lt;/p&gt;

&lt;p&gt;First off, let’s get the kubelet binary from Google.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://storage.googleapis.com/kubernetes-release/release/v1.0.3/bin/linux/amd64/kubelet
$ chmod +x kubelet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you run &lt;code&gt;./kubelet --help&lt;/code&gt;, you’ll get an overwhelming list of options. For
what we’re about to do, we only need one of them though: the &lt;code&gt;--config&lt;/code&gt; option.
This is the directory that the kubelet will watch for pod manifests to run.
We’ll create a directory for this, and then start the kubelet. You might need
to run it under &lt;code&gt;sudo&lt;/code&gt; so that it can talk to the docker daemon.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir manifests
$ ./kubelet --config=$PWD/manifests
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let’s stick the example nginx pod manifest from above in an &lt;code&gt;nginx.yaml&lt;/code&gt;
file, and then drop it in the &lt;code&gt;manifests&lt;/code&gt; directory. After a short wait, the
kubelet will notice the file and fire up the pod.&lt;/p&gt;

&lt;p&gt;We can check the list of running containers with &lt;code&gt;docker ps&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
CONTAINER ID        IMAGE                                  COMMAND                CREATED             STATUS              PORTS               NAMES
f1a27680e401        busybox:latest                         &quot;/bin/sh -c &#39;while t   6 seconds ago       Up 5 seconds                            k8s_log-truncator.72cfff7a_nginx-kx_default_419bc51e985b6bb5e53ea305e2c1e737_401a4c94   
c5e357fc981a        nginx:latest                           &quot;nginx -g &#39;daemon of   6 seconds ago       Up 6 seconds                            k8s_nginx.515d0778_nginx-kx_default_419bc51e985b6bb5e53ea305e2c1e737_cd02602b           
b2692643c372        gcr.io/google_containers/pause:0.8.0   &quot;/pause&quot;               6 seconds ago       Up 6 seconds                            k8s_POD.ef28e851_nginx-kx_default_419bc51e985b6bb5e53ea305e2c1e737_836cadc7             
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are three containers running: the &lt;code&gt;nginx&lt;/code&gt; and &lt;code&gt;log-truncator&lt;/code&gt; containers
we defined, as well as the pod infrastructure container.&lt;sup id=&quot;fnref:pause&quot;&gt;&lt;a href=&quot;#fn:pause&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; The
infrastructure container is where the kubelet puts all the resources that are
shared across containers in the pod. This includes the IP, as well as any
volumes we’ve defined. We can poke around with &lt;code&gt;docker inspect&lt;/code&gt; to see how
they’re configured and hooked up to each other:&lt;/p&gt;

&lt;!-- annoying quoting needed because liquid templates use  for something --&gt;
&lt;pre&gt;&lt;code&gt;$ docker inspect --format &#39;{{ .NetworkSettings.IPAddress  }}&#39; f1a27680e401

$ docker inspect --format &#39;{{ .NetworkSettings.IPAddress  }}&#39; c5e357fc981a

$ docker inspect --format &#39;{{ .NetworkSettings.IPAddress  }}&#39; b2692643c372
172.17.0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The nginx and log trunctator containers have no IP, but the infrastructure container does. Taking a
closer look at at the containers we defined, we can see their &lt;code&gt;NetworkMode&lt;/code&gt; is set to
use the infrastructure container’s network:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect --format &#39;{{ .HostConfig.NetworkMode  }}&#39; c5e357fc981a
container:b2692643c37216c3f1650b4a5b96254270e0489b96c022c9873ad63c4809ce93
$ docker inspect --format &#39;{{ .HostConfig.NetworkMode  }}&#39; f1a27680e401
container:b2692643c37216c3f1650b4a5b96254270e0489b96c022c9873ad63c4809ce93
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since we exposed port 80 from the nginx container with &lt;code&gt;containerPort&lt;/code&gt;,
we can connect to the nginx server at port 80 at the pod’s IP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://172.17.0.2 | head -4
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It really is running! And just to check the log truncator is doing what we
expect, let’s watch the log file and make some requests with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker exec -tty f1a27680e401 watch cat /logdir/access.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;while we make a few requests. The log lines accumulate for a bit, but then they
all disappear: the truncator doing its job!&lt;/p&gt;

&lt;h1 id=&quot;kubelet-introspection&quot;&gt;Kubelet introspection&lt;/h1&gt;

&lt;p&gt;The kubelet also has an internal HTTP server. We won’t go into it in detail,
except to say that it serves a read-only view at port
10255.  There’s a health check endpoint at &lt;code&gt;/healthz&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl http://localhost:10255/healthz
ok
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are also a few status endpoints. For example, you can get a list
of running pods at &lt;code&gt;/pods&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null http://localhost:10255/pods | jq . | head
{
  &quot;kind&quot;: &quot;PodList&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {},
  &quot;items&quot;: [
    {
      &quot;metadata&quot;: {
        &quot;name&quot;: &quot;nginx-kx&quot;,
        &quot;namespace&quot;: &quot;default&quot;,
        &quot;selfLink&quot;: &quot;/api/v1/pods/namespaces/nginx-kx/default&quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also get specs of the machine the kubelet is running on at
&lt;code&gt;/spec/&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl --stderr /dev/null  http://localhost:10255/spec/ | jq . | head
{
  &quot;num_cores&quot;: 4,
  &quot;cpu_frequency_khz&quot;: 2700000,
  &quot;memory_capacity&quot;: 4051689472,
  &quot;machine_id&quot;: &quot;9eacc5220f4b41e0a22972d8a47ccbe1&quot;,
  &quot;system_uuid&quot;: &quot;818B908B-D053-CB11-BC8B-EEA826EBA090&quot;,
  &quot;boot_id&quot;: &quot;a95a337d-6b54-4359-9a02-d50fb7377dd1&quot;,
  &quot;filesystems&quot;: [
    {
      &quot;device&quot;: &quot;/dev/mapper/kx--vg-root&quot;,
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;tearing-things-down&quot;&gt;Tearing things down&lt;/h1&gt;

&lt;p&gt;Finally, we can clean up after ourselves. Just deleting the nginx pod
manifest will result in the kubelet stopping the containers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ rm $PWD/manifests/nginx.yaml
$ sleep 20  # wait for the kublet to spot the removed manifest
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
$ curl --stderr /dev/null http://localhost:10255/pods
{&quot;kind&quot;:&quot;PodList&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;metadata&quot;:{},&quot;items&quot;:null}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All gone!&lt;/p&gt;

&lt;p&gt;We’ve seen that while the kubelet is a part of Kubernetes, at heart it’s a
container-oriented process watcher. You can use it in isolation to manage
containers running on a single host. In fact, the Kubernetes &lt;a href=&quot;http://kubernetes.io/v1.0/docs/getting-started-guides/docker.html#step-two-run-the-master&quot;&gt;getting started
guides for Docker&lt;/a&gt; run the kubelet under Docker and
use the kubelet to manage the Kubernetes master components. In a later post,
we’ll do something similar!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:pause&quot;&gt;

      &lt;p&gt;The &lt;code&gt;pause&lt;/code&gt; command that the infrastructure container runs is a 129 byte
ELF binary that just calls the &lt;a href=&quot;http://man7.org/linux/man-pages/man2/pause.2.html&quot;&gt;&lt;code&gt;pause&lt;/code&gt; system call&lt;/a&gt;, and
exits when a signal is received. This keeps the infrastructure container
around until the kubelet brings it down. It’s pretty cool, check the
&lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/88317efb42db763b9fb97cd1d9ac1465e62009d0/third_party/pause/pause.asm&quot;&gt;source&lt;/a&gt;! &lt;a href=&quot;#fnref:pause&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 27 Aug 2015 00:00:00 -0400</pubDate>
        <link>http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/</link>
        <guid isPermaLink="true">http://kamalmarhubi.com/blog/2015/08/27/what-even-is-a-kubelet/</guid>
        
        
      </item>
    
  </channel>
</rss>
